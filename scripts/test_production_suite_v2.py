#!/usr/bin/env python3
"""
ç”Ÿäº§çº§ç«¯åˆ°ç«¯æµ‹è¯•å¥—ä»¶ V2 - èšç„¦çœŸå®ç”Ÿäº§æµç¨‹
åªæµ‹è¯•E2Eæµç¨‹,ä¸æµ‹è¯•å­¤ç«‹çš„å‘é‡æ£€ç´¢(å› ä¸ºç”Ÿäº§ç¯å¢ƒä½¿ç”¨L1+L2æ··åˆç­–ç•¥)
"""
import sys
import os
import time
import json
from datetime import datetime

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.recall.graph.graph_store import GraphStore
from src.inference.zhipu_intent import ZhipuIntentRecognizer
from src.mql.sql_generator_v2 import SQLGeneratorV2
from src.inference.intent import QueryIntent, TimeGranularity, AggregationType

class ProductionTestSuiteV2:
    """ç”Ÿäº§çº§æµ‹è¯•å¥—ä»¶ V2 - èšç„¦E2Eæµç¨‹"""
    
    def __init__(self):
        self.results = {
            "graph_search": [],
            "llm_intent": [],
            "sql_generation": [],
            "e2e_flow": []
        }
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
    
    def test_graph_search(self):
        """æµ‹è¯• Neo4j å›¾è°±æ£€ç´¢ (çœŸå®)"""
        print("\n" + "="*80)
        print("ğŸ•¸ï¸  TEST 1: Graph Search (Neo4j) - Production Component")
        print("="*80)
        
        test_cases = [
            {"domain": "ç”µå•†", "min_metrics": 3},
            {"domain": "ç”¨æˆ·", "min_metrics": 3},
        ]
        
        try:
            graph_store = GraphStore()
            
            for i, case in enumerate(test_cases, 1):
                self.total_tests += 1
                print(f"\n  Test 1.{i}: Domain='{case['domain']}' -> Min Metrics={case['min_metrics']}")
                
                results = graph_store.search_by_domain(case['domain'])
                metric_count = len(results)
                
                passed = metric_count >= case['min_metrics']
                
                print(f"    Found: {metric_count} metrics")
                if results:
                    print(f"    Metrics: {[r['name'] for r in results[:5]]}")
                print(f"    Status: {'âœ… PASS' if passed else 'âŒ FAIL'}")
                
                if passed:
                    self.passed_tests += 1
                else:
                    self.failed_tests += 1
                
                self.results["graph_search"].append({
                    "domain": case['domain'],
                    "expected_min": case['min_metrics'],
                    "actual_count": metric_count,
                    "passed": passed
                })
                
            graph_store.close()
            
        except Exception as e:
            print(f"  âŒ Graph Search Test Failed: {e}")
            self.failed_tests += len(test_cases)
    
    def test_llm_intent(self):
        """æµ‹è¯• ZhipuAI LLM æ„å›¾è¯†åˆ« (çœŸå®)"""
        print("\n" + "="*80)
        print("ğŸ§  TEST 2: LLM Intent Recognition (ZhipuAI) - Production Component")
        print("="*80)
        
        test_cases = [
            {
                "query": "æœ¬æœˆæŒ‰æ¸ é“ç»Ÿè®¡DAU",
                "expected_dimensions": ["æ¸ é“"],
                "expected_time": "æœ¬æœˆ"
            },
            {
                "query": "æŒ‰åœ°åŒºçš„æˆäº¤é‡‘é¢åŒæ¯”",
                "expected_dimensions": ["åœ°åŒº"],
                "expected_comparison": "yoy"
            },
            {
                "query": "æœ€è¿‘7å¤©çš„GMV",
                "expected_time": "7",
                "expected_metric": "GMV"
            },
            {
                "query": "é”€å”®é¢è¶‹åŠ¿",
                "expected_metric": "é”€å”®é¢"
            },
        ]
        
        try:
            llm_recognizer = ZhipuIntentRecognizer(model="glm-4-flash")
            
            for i, case in enumerate(test_cases, 1):
                self.total_tests += 1
                print(f"\n  Test 2.{i}: Query='{case['query']}'")
                
                result = llm_recognizer.recognize(case['query'])
                
                if result:
                    passed = True
                    
                    # Check dimensions
                    if "expected_dimensions" in case:
                        dims_match = set(result.dimensions) == set(case['expected_dimensions'])
                        passed = passed and dims_match
                        print(f"    Dimensions: {result.dimensions} (Expected: {case['expected_dimensions']}) {'âœ…' if dims_match else 'âŒ'}")
                    
                    # Check time
                    if "expected_time" in case and result.time_range:
                        time_desc = result.time_range.get('description', '') + result.time_range.get('value', '')
                        time_match = case['expected_time'] in time_desc
                        passed = passed and time_match
                        print(f"    Time: {result.time_range} {'âœ…' if time_match else 'âŒ'}")
                    
                    # Check comparison
                    if "expected_comparison" in case:
                        comp_match = result.comparison_type == case['expected_comparison']
                        passed = passed and comp_match
                        print(f"    Comparison: {result.comparison_type} {'âœ…' if comp_match else 'âŒ'}")
                    
                    print(f"    Confidence: {result.confidence}")
                    print(f"    Status: {'âœ… PASS' if passed else 'âŒ FAIL'}")
                    
                    if passed:
                        self.passed_tests += 1
                    else:
                        self.failed_tests += 1
                    
                    self.results["llm_intent"].append({
                        "query": case['query'],
                        "passed": passed
                    })
                else:
                    print(f"    Status: âŒ FAIL (No result)")
                    self.failed_tests += 1
                    
        except Exception as e:
            print(f"  âŒ LLM Intent Test Failed: {e}")
            import traceback
            traceback.print_exc()
            self.failed_tests += len(test_cases)
    
    def test_sql_generation(self):
        """æµ‹è¯• SQL ç”Ÿæˆ (çœŸå®)"""
        print("\n" + "="*80)
        print("ğŸ“ TEST 3: SQL Generation - Production Component")
        print("="*80)
        
        test_cases = [
            {
                "name": "Simple Query",
                "intent": {
                    "query": "GMV",
                    "core_query": "GMV",
                    "time_range": (datetime(2026, 2, 1), datetime(2026, 2, 8)),
                    "time_granularity": TimeGranularity.DAY,
                    "aggregation_type": AggregationType.SUM,
                    "dimensions": [],
                    "comparison_type": None,
                    "filters": {}
                },
                "expected_keywords": ["SELECT", "FROM", "WHERE", "date"]
            },
            {
                "name": "Dimension Query",
                "intent": {
                    "query": "æŒ‰æ¸ é“ç»Ÿè®¡DAU",
                    "core_query": "DAU",
                    "time_range": (datetime(2026, 2, 1), datetime(2026, 2, 8)),
                    "time_granularity": TimeGranularity.DAY,
                    "aggregation_type": AggregationType.AVG,
                    "dimensions": ["æ¸ é“"],
                    "comparison_type": None,
                    "filters": {}
                },
                "expected_keywords": ["SELECT", "GROUP BY", "JOIN", "dim_channel"]
            },
        ]
        
        try:
            sql_generator = SQLGeneratorV2()
            
            for i, case in enumerate(test_cases, 1):
                self.total_tests += 1
                print(f"\n  Test 3.{i}: {case['name']}")
                
                query_intent = QueryIntent(**case['intent'])
                sql, params = sql_generator.generate(query_intent)
                
                passed = all(keyword in sql for keyword in case['expected_keywords'])
                
                print(f"    SQL Length: {len(sql)} chars")
                print(f"    Keywords Check: {case['expected_keywords']}")
                for keyword in case['expected_keywords']:
                    found = keyword in sql
                    print(f"      - {keyword}: {'âœ…' if found else 'âŒ'}")
                
                print(f"    Status: {'âœ… PASS' if passed else 'âŒ FAIL'}")
                
                if passed:
                    self.passed_tests += 1
                else:
                    self.failed_tests += 1
                
                self.results["sql_generation"].append({
                    "name": case['name'],
                    "passed": passed
                })
                
        except Exception as e:
            print(f"  âŒ SQL Generation Test Failed: {e}")
            import traceback
            traceback.print_exc()
            self.failed_tests += len(test_cases)
    
    def test_e2e_flow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹ (çœŸå®) - æ‰©å±•æµ‹è¯•ç”¨ä¾‹"""
        print("\n" + "="*80)
        print("ğŸ”„ TEST 4: End-to-End Production Flow (Extended)")
        print("="*80)
        
        import requests
        
        test_cases = [
            {"query": "æœ€è¿‘7å¤©çš„GMV", "expected_metric": "GMV"},
            {"query": "æœ¬æœˆæŒ‰æ¸ é“ç»Ÿè®¡DAU", "expected_metric": "DAU", "expected_dims": ["æ¸ é“"]},
            {"query": "ç”µå•†è®¢å•é‡", "expected_metric": "è®¢å•é‡"},
            {"query": "é”€å”®é¢", "expected_metric": "GMV"},  # é€šè¿‡L1åŒä¹‰è¯åŒ¹é…
            {"query": "è®¢å•æ•°é‡", "expected_metric": "è®¢å•é‡"},  # é€šè¿‡L1åŒä¹‰è¯åŒ¹é…
            {"query": "ç”¨æˆ·ç•™å­˜", "expected_metric": "ç•™å­˜ç‡"},  # é€šè¿‡L1åŒä¹‰è¯åŒ¹é…
            {"query": "æŠ•èµ„å›æŠ¥", "expected_metric": "ROI"},  # é€šè¿‡L1åŒä¹‰è¯åŒ¹é…
            {"query": "æ—¥æ´»ç”¨æˆ·", "expected_metric": "DAU"},  # é€šè¿‡L1åŒä¹‰è¯åŒ¹é…
        ]
        
        for i, case in enumerate(test_cases, 1):
            self.total_tests += 1
            print(f"\n  Test 4.{i}: Query='{case['query']}'")
            
            try:
                response = requests.post(
                    "http://localhost:8000/api/v3/query",
                    json={"query": case['query']},
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Check metric
                    metric_match = case['expected_metric'] in data['intent']['core_query']
                    print(f"    Metric: {data['intent']['core_query']} {'âœ…' if metric_match else 'âŒ'}")
                    
                    # Check dimensions
                    dims_match = True
                    if "expected_dims" in case:
                        dims_match = set(data['intent']['dimensions']) == set(case['expected_dims'])
                        print(f"    Dimensions: {data['intent']['dimensions']} {'âœ…' if dims_match else 'âŒ'}")
                    
                    # Check SQL generated
                    sql_generated = data.get('sql') and data['sql'] != "-- SQL generation failed"
                    print(f"    SQL Generated: {'âœ…' if sql_generated else 'âŒ'}")
                    
                    # Check data returned
                    data_returned = len(data.get('data', [])) > 0
                    print(f"    Data Returned: {len(data.get('data', []))} records {'âœ…' if data_returned else 'âŒ'}")
                    
                    passed = metric_match and dims_match and sql_generated and data_returned
                    
                    print(f"    Status: {'âœ… PASS' if passed else 'âŒ FAIL'}")
                    
                    if passed:
                        self.passed_tests += 1
                    else:
                        self.failed_tests += 1
                    
                    self.results["e2e_flow"].append({
                        "query": case['query'],
                        "metric": data['intent']['core_query'],
                        "passed": passed
                    })
                else:
                    print(f"    Status: âŒ FAIL (HTTP {response.status_code})")
                    self.failed_tests += 1
                    
            except Exception as e:
                print(f"    Status: âŒ FAIL ({e})")
                self.failed_tests += 1
    def test_e2e_adversarial_flow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹ (å¹²æ‰°æ€§/å¯¹æŠ—æ€§æµ‹è¯•)"""
        print("\n" + "="*80)
        print("âš”ï¸  TEST 5: E2E Adversarial Flow (High Interference)")
        print("="*80)
        
        import requests
        
        # å¹²æ‰°æ€§æµ‹è¯•ç”¨ä¾‹ (Expect strict Name match)
        test_cases = [
            # 1. è®¢å•é‡å¹²æ‰°ç»„
            {"query": "æœ‰æ•ˆè®¢å•é‡", "expected_name": "æœ‰æ•ˆè®¢å•é‡", "forbidden_name": "è®¢å•é‡"},
            {"query": "æ”¯ä»˜è®¢å•é‡", "expected_name": "æ”¯ä»˜è®¢å•é‡", "forbidden_name": "è®¢å•é‡"},
            {"query": "é€€æ¬¾è®¢å•é‡", "expected_name": "é€€æ¬¾è®¢å•é‡", "forbidden_name": "è®¢å•é‡"},
            
            # 2. GMVå¹²æ‰°ç»„
            {"query": "é¢„æµ‹GMV", "expected_name": "é¢„æµ‹GMV", "forbidden_name": "GMV"}, # "GMV" might be substring of "é¢„æµ‹GMV", so we need strict check
            {"query": "æ—¥å‡GMV", "expected_name": "æ—¥å‡GMV", "forbidden_name": "GMV"},
            
            # 3. è½¬åŒ–ç‡å¹²æ‰°ç»„
            {"query": "ç‚¹å‡»è½¬åŒ–ç‡", "expected_name": "ç‚¹å‡»è½¬åŒ–ç‡", "forbidden_name": "è½¬åŒ–ç‡"},
            {"query": "æ”¯ä»˜è½¬åŒ–ç‡", "expected_name": "æ”¯ä»˜è½¬åŒ–ç‡", "forbidden_name": "è½¬åŒ–ç‡"},
            
            # 4. ç‰©æµå¹²æ‰°ç»„ (è¯­ä¹‰ç›¸è¿‘)
            {"query": "å‘è´§æ—¶é•¿", "expected_name": "å‘è´§æ—¶é•¿", "forbidden_name": "é…é€æ—¶é•¿"},
            {"query": "é…é€æ—¶é•¿", "expected_name": "é…é€æ—¶é•¿", "forbidden_name": "å‘è´§æ—¶é•¿"},
            
            # 5. è´¢åŠ¡å¹²æ‰°ç»„
            {"query": "å‡€åˆ©", "expected_name": "å‡€åˆ©", "forbidden_name": "æ¯›åˆ©"},
            {"query": "æ¯›åˆ©", "expected_name": "æ¯›åˆ©", "forbidden_name": "å‡€åˆ©"},
        ]
        
        for i, case in enumerate(test_cases, 1):
            self.total_tests += 1
            print(f"\n  Test 5.{i}: Query='{case['query']}'")
            
            try:
                response = requests.post(
                    "http://localhost:8000/api/v3/query",
                    json={"query": case['query']},
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    metric_name = data['intent']['core_query']
                    
                    # Strict validation
                    metric_match = metric_name == case['expected_name']
                    
                    # Forbidden check: The identified metric Name should NOT be the forbidden one
                    # e.g. if we want "Valid Order Count", we don't want "Order Count"
                    forbidden_match = metric_name == case['forbidden_name']
                    
                    print(f"    Metric Name: {metric_name}")
                    print(f"    Expected: {case['expected_name']} {'âœ…' if metric_match else 'âŒ'}")
                    print(f"    Forbidden: {case['forbidden_name']} {'âœ…' if not forbidden_match else 'âŒ (Found Forbidden!)'}")
                    
                    passed = metric_match and not forbidden_match
                    
                    print(f"    Status: {'âœ… PASS' if passed else 'âŒ FAIL'}")
                    
                    if passed:
                        self.passed_tests += 1
                    else:
                        self.failed_tests += 1
                    
                    self.results["e2e_flow"].append({
                        "query": case['query'],
                        "metric": metric_name,
                        "passed": passed,
                        "type": "adversarial"
                    })
                else:
                    print(f"    Status: âŒ FAIL (HTTP {response.status_code})")
                    self.failed_tests += 1
                    
            except Exception as e:
                print(f"    Status: âŒ FAIL ({e})")
                self.failed_tests += 1
    def run_all_tests(self, iterations=2):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯• (æŒ‡å®šæ¬¡æ•°)"""
        print("\n" + "ğŸš€"*40)
        print(f"ç”Ÿäº§çº§æµ‹è¯•å¥—ä»¶ V2 - Running {iterations} iterations")
        print("èšç„¦E2Eæµç¨‹ - çœŸå®ç”Ÿäº§åœºæ™¯")
        print("ğŸš€"*40)
        
        for iteration in range(1, iterations + 1):
            print(f"\n{'#'*80}")
            print(f"# ITERATION {iteration}/{iterations}")
            print(f"{'#'*80}")
            
            self.test_graph_search()
            self.test_llm_intent()
            self.test_sql_generation()
            self.test_e2e_flow()
            self.test_e2e_adversarial_flow()
            
            if iteration < iterations:
                print(f"\nâ³ Waiting 3 seconds before next iteration...")
                time.sleep(3)
        
        self.print_summary()
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*80)
        print("ğŸ“Š TEST SUMMARY")
        print("="*80)
        
        print(f"\nTotal Tests: {self.total_tests}")
        print(f"âœ… Passed: {self.passed_tests}")
        print(f"âŒ Failed: {self.failed_tests}")
        print(f"Success Rate: {(self.passed_tests/self.total_tests*100):.1f}%")
        
        print("\n" + "="*80)
        
        if self.failed_tests == 0:
            print("ğŸ‰ ALL TESTS PASSED - PRODUCTION READY!")
        else:
            print("âš ï¸  SOME TESTS FAILED - REVIEW REQUIRED")
        
        print("="*80 + "\n")
        
        # Save results
        with open('test_results_v2.json', 'w', encoding='utf-8') as f:
            json.dump({
                "summary": {
                    "total": self.total_tests,
                    "passed": self.passed_tests,
                    "failed": self.failed_tests,
                    "success_rate": self.passed_tests/self.total_tests*100
                },
                "details": self.results
            }, f, ensure_ascii=False, indent=2)
        
        print("ğŸ“„ Detailed results saved to: test_results_v2.json\n")

if __name__ == "__main__":
    suite = ProductionTestSuiteV2()
    suite.run_all_tests(iterations=2)
