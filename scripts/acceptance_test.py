"""é¡¹ç›®éªŒæ”¶æµ‹è¯•è„šæœ¬.

æµ‹è¯•å®Œæ•´çš„åŠŸèƒ½ï¼ˆä¸éœ€è¦PostgreSQLè¿è¡Œï¼‰ï¼š
1. æ¨¡å—å¯¼å…¥æµ‹è¯•
2. SQLç”Ÿæˆå™¨æµ‹è¯•
3. æ™ºèƒ½è§£è¯»å™¨æµ‹è¯•ï¼ˆå«æ¨¡æ‹Ÿæ•°æ®ï¼‰
4. é™çº§æœºåˆ¶æµ‹è¯•
"""

import logging
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_module_imports():
    """æµ‹è¯•1: æ¨¡å—å¯¼å…¥."""
    print("\n" + "=" * 60)
    print("ğŸ“¦ æµ‹è¯•1: æ¨¡å—å¯¼å…¥")
    print("=" * 60)

    try:
        from src.database.postgres_client import PostgreSQLClient
        print("âœ… PostgreSQLå®¢æˆ·ç«¯")

        from src.mql.sql_generator import SQLGenerator
        print("âœ… SQLç”Ÿæˆå™¨")

        from src.mql.intelligent_interpreter import IntelligentInterpreter
        print("âœ… æ™ºèƒ½è§£è¯»å™¨")

        from src.mql.models import InterpretationResult
        print("âœ… MQLæ•°æ®æ¨¡å‹")

        from src.api.v2_query_api import create_app
        print("âœ… APIæœåŠ¡")

        print("\nâœ… æ‰€æœ‰æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True

    except Exception as e:
        print(f"\nâŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_sql_generator():
    """æµ‹è¯•2: SQLç”Ÿæˆå™¨."""
    print("\n" + "=" * 60)
    print("ğŸ”§ æµ‹è¯•2: SQLç”Ÿæˆå™¨")
    print("=" * 60)

    try:
        from src.mql.sql_generator import SQLGenerator
        from src.mql.mql import MQLQuery, MetricOperator, TimeRange

        generator = SQLGenerator()

        # æµ‹è¯•èšåˆæŸ¥è¯¢
        mql_query = MQLQuery(
            metric="GMV",
            operator=MetricOperator.SUM,
            time_range=TimeRange(
                start=datetime(2024, 1, 1),
                end=datetime(2024, 1, 7),
                granularity="day"
            )
        )

        sql, params = generator.generate(mql_query)

        print(f"\nç”Ÿæˆçš„SQL:")
        print(f"  {sql[:100]}...")
        print(f"\nå‚æ•°:")
        print(f"  {params}")

        # éªŒè¯SQLåŒ…å«å…³é”®å…ƒç´ 
        assert "SUM" in sql, "SQLåº”åŒ…å«SUMèšåˆ"
        assert "fact_orders" in sql, "SQLåº”å¼•ç”¨è®¢å•äº‹å®è¡¨"
        assert "BETWEEN" in sql, "SQLåº”åŒ…å«æ—¶é—´èŒƒå›´è¿‡æ»¤"

        print("\nâœ… SQLç”Ÿæˆå™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"\nâŒ SQLç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_intelligent_interpreter():
    """æµ‹è¯•3: æ™ºèƒ½è§£è¯»å™¨."""
    print("\n" + "=" * 60)
    print("ğŸ¤– æµ‹è¯•3: æ™ºèƒ½è§£è¯»å™¨")
    print("=" * 60)

    try:
        from src.mql.intelligent_interpreter import IntelligentInterpreter

        interpreter = IntelligentInterpreter()

        # ç”Ÿæˆä¸Šå‡è¶‹åŠ¿çš„æ¨¡æ‹Ÿæ•°æ®
        mock_data = []
        for i in range(7):
            mock_data.append({
                "date": (datetime.now() - timedelta(days=6-i)).strftime("%Y-%m-%d"),
                "value": 500000 + i * 30000,  # ä¸Šå‡è¶‹åŠ¿
                "metric": "GMV",
                "unit": "å…ƒ"
            })

        metric_def = {
            "name": "GMV",
            "description": "å•†å“äº¤æ˜“æ€»é¢",
            "unit": "å…ƒ"
        }

        mql_result = {
            "result": mock_data,
            "row_count": len(mock_data)
        }

        # æ‰§è¡Œè§£è¯»
        interpretation = interpreter.interpret(
            query="æœ€è¿‘7å¤©GMV",
            mql_result=mql_result,
            metric_def=metric_def
        )

        print(f"\nè§£è¯»ç»“æœ:")
        print(f"  æ€»ç»“: {interpretation.summary}")
        print(f"  è¶‹åŠ¿: {interpretation.trend}")
        print(f"  ç½®ä¿¡åº¦: {interpretation.confidence:.2f}")
        print(f"\n  å…³é”®å‘ç°:")
        for finding in interpretation.key_findings[:2]:
            print(f"    - {finding}")
        print(f"\n  æ·±å…¥æ´å¯Ÿ:")
        for insight in interpretation.insights[:2]:
            print(f"    - {insight}")
        print(f"\n  è¡ŒåŠ¨å»ºè®®:")
        for suggestion in interpretation.suggestions[:2]:
            print(f"    - {suggestion}")

        # éªŒè¯è§£è¯»ç»“æœ
        assert interpretation.trend == "upward", "åº”è¯†åˆ«ä¸ºä¸Šå‡è¶‹åŠ¿"
        assert interpretation.summary is not None, "æ€»ç»“ä¸åº”ä¸ºç©º"
        assert len(interpretation.key_findings) > 0, "åº”æœ‰å…³é”®å‘ç°"
        assert len(interpretation.insights) > 0, "åº”æœ‰æ·±å…¥æ´å¯Ÿ"
        assert len(interpretation.suggestions) > 0, "åº”æœ‰è¡ŒåŠ¨å»ºè®®"
        assert 0 <= interpretation.confidence <= 1, "ç½®ä¿¡åº¦åº”åœ¨0-1ä¹‹é—´"

        print("\nâœ… æ™ºèƒ½è§£è¯»å™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"\nâŒ æ™ºèƒ½è§£è¯»å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_fallback_mechanism():
    """æµ‹è¯•4: é™çº§æœºåˆ¶."""
    print("\n" + "=" * 60)
    print("ğŸ›¡ï¸ æµ‹è¯•4: é™çº§æœºåˆ¶")
    print("=" * 60)

    try:
        from src.mql.intelligent_interpreter import IntelligentInterpreter

        interpreter = IntelligentInterpreter()

        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        mock_data = []
        for i in range(7):
            mock_data.append({
                "date": (datetime.now() - timedelta(days=6-i)).strftime("%Y-%m-%d"),
                "value": 500000 + i * 20000,
                "metric": "GMV",
                "unit": "å…ƒ"
            })

        metric_def = {
            "name": "GMV",
            "description": "å•†å“äº¤æ˜“æ€»é¢",
            "unit": "å…ƒ"
        }

        mql_result = {
            "result": mock_data,
            "row_count": len(mock_data)
        }

        # ä½¿ç”¨æ¨¡æ¿è§£è¯»ï¼ˆæ¨¡æ‹ŸLLMå¤±è´¥ï¼‰
        interpretation = interpreter._generate_template_interpretation(
            query="æœ€è¿‘7å¤©GMV",
            data_analysis=interpreter._analyze_data(mock_data),
            metric_def=metric_def,
            mql_result=mql_result
        )

        print(f"\næ¨¡æ¿è§£è¯»ç»“æœ:")
        print(f"  æ€»ç»“: {interpretation.summary}")
        print(f"  å…³é”®å‘ç°æ•°é‡: {len(interpretation.key_findings)}")
        print(f"  æ·±å…¥æ´å¯Ÿæ•°é‡: {len(interpretation.insights)}")
        print(f"  è¡ŒåŠ¨å»ºè®®æ•°é‡: {len(interpretation.suggestions)}")

        # éªŒè¯æ¨¡æ¿è§£è¯»
        assert interpretation.summary is not None, "æ€»ç»“ä¸åº”ä¸ºç©º"
        assert len(interpretation.key_findings) > 0, "åº”æœ‰å…³é”®å‘ç°"
        assert len(interpretation.insights) > 0, "åº”æœ‰æ·±å…¥æ´å¯Ÿ"
        assert len(interpretation.suggestions) > 0, "åº”æœ‰è¡ŒåŠ¨å»ºè®®"

        print("\nâœ… é™çº§æœºåˆ¶æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"\nâŒ é™çº§æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_analysis():
    """æµ‹è¯•5: æ•°æ®åˆ†æ."""
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•5: æ•°æ®åˆ†æ")
    print("=" * 60)

    try:
        from src.mql.intelligent_interpreter import IntelligentInterpreter

        interpreter = IntelligentInterpreter()

        # ä¸Šå‡è¶‹åŠ¿æ•°æ®
        upward_data = [{"value": 100 + i * 10} for i in range(10)]
        analysis = interpreter._analyze_data(upward_data)

        print(f"\nä¸Šå‡è¶‹åŠ¿åˆ†æ:")
        print(f"  è¶‹åŠ¿: {analysis['trend']}")
        print(f"  å˜åŒ–ç‡: {analysis['change_rate']:.2f}%")
        print(f"  æ³¢åŠ¨æ€§: {analysis['volatility']:.2f}%")

        assert analysis["trend"] == "upward", "åº”è¯†åˆ«ä¸ºä¸Šå‡è¶‹åŠ¿"
        assert analysis["change_rate"] > 0, "å˜åŒ–ç‡åº”å¤§äº0"

        # ä¸‹é™è¶‹åŠ¿æ•°æ®
        downward_data = [{"value": 200 - i * 10} for i in range(10)]
        analysis = interpreter._analyze_data(downward_data)

        print(f"\nä¸‹é™è¶‹åŠ¿åˆ†æ:")
        print(f"  è¶‹åŠ¿: {analysis['trend']}")
        print(f"  å˜åŒ–ç‡: {analysis['change_rate']:.2f}%")

        assert analysis["trend"] == "downward", "åº”è¯†åˆ«ä¸ºä¸‹é™è¶‹åŠ¿"

        # ç¨³å®šæ•°æ®
        stable_data = [{"value": 100 + (i % 2) * 2} for i in range(10)]
        analysis = interpreter._analyze_data(stable_data)

        print(f"\nç¨³å®šæ•°æ®åˆ†æ:")
        print(f"  è¶‹åŠ¿: {analysis['trend']}")
        print(f"  å˜åŒ–ç‡: {analysis['change_rate']:.2f}%")

        assert analysis["trend"] == "stable", "åº”è¯†åˆ«ä¸ºç¨³å®šè¶‹åŠ¿"

        print("\nâœ… æ•°æ®åˆ†ææµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"\nâŒ æ•°æ®åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°."""
    print("\nğŸš€ é¡¹ç›®éªŒæ”¶æµ‹è¯•")
    print("=" * 60)
    print("æ³¨æ„ï¼šæ­¤æµ‹è¯•ä¸éœ€è¦PostgreSQLè¿è¡Œ")
    print("=" * 60)

    tests = [
        ("æ¨¡å—å¯¼å…¥", test_module_imports),
        ("SQLç”Ÿæˆå™¨", test_sql_generator),
        ("æ™ºèƒ½è§£è¯»å™¨", test_intelligent_interpreter),
        ("é™çº§æœºåˆ¶", test_fallback_mechanism),
        ("æ•°æ®åˆ†æ", test_data_analysis),
    ]

    passed = 0
    failed = 0

    for name, test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"\nâŒ {name}æµ‹è¯•å¼‚å¸¸: {e}")
            failed += 1

    print("\n" + "=" * 60)
    print(f"æµ‹è¯•ç»“æœ: {passed}é€šè¿‡, {failed}å¤±è´¥")
    print("=" * 60)

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰éªŒæ”¶æµ‹è¯•é€šè¿‡ï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. å®‰è£…Docker Desktop (å¦‚æœªå®‰è£…)")
        print("  2. å¯åŠ¨æœåŠ¡: docker compose up -d")
        print("  3. åˆå§‹åŒ–æ•°æ®: python scripts/init_test_data.py")
        print("  4. è¿è¡Œé›†æˆæµ‹è¯•: python scripts/test_postgres_integration.py")
        print("  5. å¯åŠ¨API: python -m src.api.v2_query_api")
        print("\nè¯¦ç»†æ–‡æ¡£: docs/POSTGRESQL_INTEGRATION.md")
        print("=" * 60 + "\n")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("=" * 60 + "\n")

    return failed == 0


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
