"""æµ‹è¯•æ•°æ®åˆå§‹åŒ–è„šæœ¬.

ä¸ºPostgreSQLæ•°æ®åº“ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
- ç»´åº¦è¡¨æ•°æ®ï¼ˆå·²åœ¨Schemaä¸­åˆå§‹åŒ–ï¼‰
- äº‹å®è¡¨æ•°æ®ï¼ˆè®¢å•ã€ç”¨æˆ·æ´»åŠ¨ã€æµé‡ã€è¥æ”¶ï¼‰
"""

import logging
import random
from datetime import datetime, timedelta

from src.database.postgres_client import PostgreSQLClient
from src.config import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TestDataInitializer:
    """æµ‹è¯•æ•°æ®åˆå§‹åŒ–å™¨."""

    def __init__(self):
        """åˆå§‹åŒ–."""
        self.postgres = PostgreSQLClient()

    def init_all_data(self, days: int = 30):
        """åˆå§‹åŒ–æ‰€æœ‰æµ‹è¯•æ•°æ®.

        Args:
            days: ç”Ÿæˆæ•°æ®çš„å¤©æ•°ï¼ˆé»˜è®¤30å¤©ï¼‰
        """
        logger.info(f"å¼€å§‹åˆå§‹åŒ–æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰")

        try:
            # 1. åˆå§‹åŒ–è®¢å•æ•°æ®
            self._init_order_data(days)
            logger.info("âœ… è®¢å•æ•°æ®åˆå§‹åŒ–å®Œæˆ")

            # 2. åˆå§‹åŒ–ç”¨æˆ·æ´»åŠ¨æ•°æ®
            self._init_user_activity_data(days)
            logger.info("âœ… ç”¨æˆ·æ´»åŠ¨æ•°æ®åˆå§‹åŒ–å®Œæˆ")

            # 3. åˆå§‹åŒ–æµé‡æ•°æ®
            self._init_traffic_data(days)
            logger.info("âœ… æµé‡æ•°æ®åˆå§‹åŒ–å®Œæˆ")

            # 4. åˆå§‹åŒ–è¥æ”¶æ•°æ®
            self._init_revenue_data(days)
            logger.info("âœ… è¥æ”¶æ•°æ®åˆå§‹åŒ–å®Œæˆ")

            # 5. åˆå§‹åŒ–è´¢åŠ¡æ•°æ®
            self._init_finance_data(days)
            logger.info("âœ… è´¢åŠ¡æ•°æ®åˆå§‹åŒ–å®Œæˆ")

            logger.info("\n" + "=" * 60)
            logger.info("æ‰€æœ‰æµ‹è¯•æ•°æ®åˆå§‹åŒ–å®Œæˆï¼")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _init_order_data(self, days: int):
        """åˆå§‹åŒ–è®¢å•äº‹å®è¡¨æ•°æ®.

        ç”Ÿæˆçº¦10,000æ¡è®¢å•è®°å½•ï¼ˆçº¦330æ¡/å¤©ï¼‰
        """
        logger.info("æ­£åœ¨ç”Ÿæˆè®¢å•æ•°æ®...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        batch_size = 1000
        batch = []
        order_id = 1000000

        current_date = start_date
        while current_date <= end_date:
            # æ¯å¤©ç”Ÿæˆçº¦330æ¡è®¢å•
            for _ in range(330):
                order_id += 1

                # éšæœºç”Ÿæˆè®¢å•æ•°æ®
                order_amount = random.uniform(50, 5000)
                # å‘¨æœ«å’ŒèŠ‚å‡æ—¥è®¢å•é‡å¢åŠ 
                if current_date.weekday() >= 5:
                    order_amount *= random.uniform(1.1, 1.3)

                batch.append({
                    "order_id": order_id,
                    "date_id": current_date.strftime("%Y-%m-%d"),
                    "region_id": random.randint(1, 5),  # 5ä¸ªåœ°åŒº
                    "category_id": random.randint(1, 6),  # 6ä¸ªå“ç±»
                    "channel_id": random.randint(1, 4),  # 4ä¸ªæ¸ é“
                    "user_level_id": random.randint(1, 4),  # 4ä¸ªç”¨æˆ·ç­‰çº§
                    "order_amount": round(order_amount, 2),
                    "quantity": random.randint(1, 5),
                    "is_paid": random.choice([True, True, True, False]),  # 75%æ”¯ä»˜ç‡
                    "is_refunded": random.choice([True, False, False, False, False])  # 20%é€€æ¬¾ç‡
                })

                # æ‰¹é‡æ’å…¥
                if len(batch) >= batch_size:
                    self._batch_insert_orders(batch)
                    batch = []

            current_date += timedelta(days=1)

        # æ’å…¥å‰©ä½™æ•°æ®
        if batch:
            self._batch_insert_orders(batch)

    def _batch_insert_orders(self, batch: list):
        """æ‰¹é‡æ’å…¥è®¢å•æ•°æ®."""
        sql = """
            INSERT INTO fact_orders (
                order_id, date_id, region_id, category_id, channel_id,
                user_level_id, order_amount, quantity, is_paid, is_refunded
            ) VALUES (
                %(order_id)s, %(date_id)s, %(region_id)s, %(category_id)s,
                %(channel_id)s, %(user_level_id)s, %(order_amount)s,
                %(quantity)s, %(is_paid)s, %(is_refunded)s
            )
        """
        self.postgres.execute_batch(sql, batch)

    def _init_user_activity_data(self, days: int):
        """åˆå§‹åŒ–ç”¨æˆ·æ´»åŠ¨äº‹å®è¡¨æ•°æ®.

        ç”Ÿæˆçº¦50,000æ¡è®°å½•ï¼ˆçº¦1,600æ¡/å¤©ï¼‰
        """
        logger.info("æ­£åœ¨ç”Ÿæˆç”¨æˆ·æ´»åŠ¨æ•°æ®...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        batch_size = 1000
        batch = []
        activity_id = 2000000

        current_date = start_date
        while current_date <= end_date:
            # æ¯å¤©ç”Ÿæˆçº¦1,600æ¡æ´»åŠ¨è®°å½•
            for _ in range(1600):
                activity_id += 1

                is_new_user = random.choice([True] * 10 + [False] * 90)  # 10%æ–°ç”¨æˆ·

                batch.append({
                    "activity_id": activity_id,
                    "date_id": current_date.strftime("%Y-%m-%d"),
                    "region_id": random.randint(1, 5),
                    "channel_id": random.randint(1, 4),
                    "user_level_id": random.randint(1, 4),
                    "user_id": random.randint(10000, 99999),
                    "is_new_user": is_new_user,
                    "activity_count": random.randint(1, 10),
                    "session_duration_seconds": random.randint(30, 3600),
                    "page_views": random.randint(1, 50)
                })

                if len(batch) >= batch_size:
                    self._batch_insert_user_activities(batch)
                    batch = []

            current_date += timedelta(days=1)

        if batch:
            self._batch_insert_user_activities(batch)

    def _batch_insert_user_activities(self, batch: list):
        """æ‰¹é‡æ’å…¥ç”¨æˆ·æ´»åŠ¨æ•°æ®."""
        sql = """
            INSERT INTO fact_user_activity (
                activity_id, date_id, region_id, channel_id, user_level_id,
                user_id, is_new_user, activity_count, session_duration_seconds, page_views
            ) VALUES (
                %(activity_id)s, %(date_id)s, %(region_id)s, %(channel_id)s,
                %(user_level_id)s, %(user_id)s, %(is_new_user)s,
                %(activity_count)s, %(session_duration_seconds)s, %(page_views)s
            )
        """
        self.postgres.execute_batch(sql, batch)

    def _init_traffic_data(self, days: int):
        """åˆå§‹åŒ–æµé‡äº‹å®è¡¨æ•°æ®.

        ç”Ÿæˆçº¦30,000æ¡è®°å½•ï¼ˆçº¦1,000æ¡/å¤©ï¼‰
        """
        logger.info("æ­£åœ¨ç”Ÿæˆæµé‡æ•°æ®...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        batch_size = 1000
        batch = []
        traffic_id = 3000000

        current_date = start_date
        while current_date <= end_date:
            # æ¯å¤©ç”Ÿæˆçº¦1,000æ¡æµé‡è®°å½•
            for _ in range(1000):
                traffic_id += 1

                visitors = random.randint(100, 1000)
                batch.append({
                    "traffic_id": traffic_id,
                    "date_id": current_date.strftime("%Y-%m-%d"),
                    "region_id": random.randint(1, 5),
                    "category_id": random.randint(1, 6),
                    "channel_id": random.randint(1, 4),
                    "visitors": visitors,
                    "visits": random.randint(visitors, visitors * 2),
                    "page_views": random.randint(visitors * 2, visitors * 10),
                    "unique_visitors": random.randint(int(visitors * 0.8), visitors),
                    "cart_additions": random.randint(0, int(visitors * 0.3)),
                    "orders": random.randint(0, int(visitors * 0.1)),
                    "paid_orders": random.randint(0, int(visitors * 0.08))
                })

                if len(batch) >= batch_size:
                    self._batch_insert_traffic(batch)
                    batch = []

            current_date += timedelta(days=1)

        if batch:
            self._batch_insert_traffic(batch)

    def _batch_insert_traffic(self, batch: list):
        """æ‰¹é‡æ’å…¥æµé‡æ•°æ®."""
        sql = """
            INSERT INTO fact_traffic (
                traffic_id, date_id, region_id, category_id, channel_id,
                visitors, visits, page_views, unique_visitors,
                cart_additions, orders, paid_orders
            ) VALUES (
                %(traffic_id)s, %(date_id)s, %(region_id)s, %(category_id)s,
                %(channel_id)s, %(visitors)s, %(visits)s, %(page_views)s,
                %(unique_visitors)s, %(cart_additions)s, %(orders)s, %(paid_orders)s
            )
        """
        self.postgres.execute_batch(sql, batch)

    def _init_revenue_data(self, days: int):
        """åˆå§‹åŒ–è¥æ”¶äº‹å®è¡¨æ•°æ®.

        ç”Ÿæˆçº¦1,000æ¡è®°å½•ï¼ˆçº¦35æ¡/å¤©ï¼ŒæŒ‰åœ°åŒº+æ¸ é“åˆ†ç»„ï¼‰
        """
        logger.info("æ­£åœ¨ç”Ÿæˆè¥æ”¶æ•°æ®...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        batch_size = 500
        batch = []
        revenue_id = 4000000

        current_date = start_date
        while current_date <= end_date:
            # æ¯å¤©æŒ‰åœ°åŒº+æ¸ é“ç»„åˆç”Ÿæˆæ•°æ®ï¼ˆ5åœ°åŒº * 4æ¸ é“ = 20æ¡/å¤©ï¼‰
            for region_id in range(1, 6):
                for channel_id in range(1, 5):
                    for user_level_id in range(1, 5):
                        revenue_id += 1

                        revenue = random.uniform(10000, 100000)
                        cost = revenue * random.uniform(0.3, 0.7)

                        batch.append({
                            "revenue_id": revenue_id,
                            "date_id": current_date.strftime("%Y-%m-%d"),
                            "region_id": region_id,
                            "channel_id": channel_id,
                            "user_level_id": user_level_id,
                            "revenue": round(revenue, 2),
                            "cost": round(cost, 2)
                        })

                        if len(batch) >= batch_size:
                            self._batch_insert_revenue(batch)
                            batch = []

            current_date += timedelta(days=1)

        if batch:
            self._batch_insert_revenue(batch)

    def _batch_insert_revenue(self, batch: list):
        """æ‰¹é‡æ’å…¥è¥æ”¶æ•°æ®."""
        sql = """
            INSERT INTO fact_revenue (
                revenue_id, date_id, region_id, channel_id, user_level_id,
                revenue, cost
            ) VALUES (
                %(revenue_id)s, %(date_id)s, %(region_id)s, %(channel_id)s,
                %(user_level_id)s, %(revenue)s, %(cost)s
            )
        """
        self.postgres.execute_batch(sql, batch)

    def _init_finance_data(self, days: int):
        """åˆå§‹åŒ–è´¢åŠ¡äº‹å®è¡¨æ•°æ®.

        ç”Ÿæˆçº¦2,000æ¡è®°å½•ï¼ˆçº¦70æ¡/å¤©ï¼ŒæŒ‰åœ°åŒº+ä¸šåŠ¡çº¿ç»„åˆï¼‰
        """
        logger.info("æ­£åœ¨ç”Ÿæˆè´¢åŠ¡æ•°æ®...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        batch_size = 500
        batch = []
        finance_id = 5000000

        business_lines = ["ç”µå•†", "SaaS", "å¹¿å‘Š", "å’¨è¯¢", "å…¶ä»–"]
        products = ["äº§å“A", "äº§å“B", "äº§å“C", "æœåŠ¡D", "æœåŠ¡E"]

        current_date = start_date
        while current_date <= end_date:
            # æ¯å¤©æŒ‰åœ°åŒº+ä¸šåŠ¡çº¿+äº§å“ç»„åˆç”Ÿæˆæ•°æ®
            for region_id in range(1, 6):
                for business_line in business_lines:
                    for product in products:
                        finance_id += 1

                        revenue = random.uniform(5000, 50000)
                        cost = revenue * random.uniform(0.4, 0.8)

                        batch.append({
                            "finance_id": finance_id,
                            "date_id": current_date.strftime("%Y-%m-%d"),
                            "region_id": region_id,
                            "business_line": business_line,
                            "product_name": product,
                            "revenue": round(revenue, 2),
                            "cost": round(cost, 2)
                        })

                        if len(batch) >= batch_size:
                            self._batch_insert_finance(batch)
                            batch = []

            current_date += timedelta(days=1)

        if batch:
            self._batch_insert_finance(batch)

    def _batch_insert_finance(self, batch: list):
        """æ‰¹é‡æ’å…¥è´¢åŠ¡æ•°æ®."""
        sql = """
            INSERT INTO fact_finance (
                finance_id, date_id, region_id, business_line, product_name,
                revenue, cost
            ) VALUES (
                %(finance_id)s, %(date_id)s, %(region_id)s, %(business_line)s,
                %(product_name)s, %(revenue)s, %(cost)s
            )
        """
        self.postgres.execute_batch(sql, batch)


def main():
    """ä¸»å‡½æ•°."""
    print("\nğŸš€ æµ‹è¯•æ•°æ®åˆå§‹åŒ–")
    print("=" * 60)

    initializer = TestDataInitializer()

    try:
        # ç”Ÿæˆ30å¤©çš„æµ‹è¯•æ•°æ®
        initializer.init_all_data(days=30)

        print("\nâœ… æ•°æ®åˆå§‹åŒ–å®Œæˆï¼")
        print(f"   è®¢å•äº‹å®è¡¨: ~10,000æ¡")
        print(f"   ç”¨æˆ·æ´»åŠ¨äº‹å®è¡¨: ~50,000æ¡")
        print(f"   æµé‡äº‹å®è¡¨: ~30,000æ¡")
        print(f"   è¥æ”¶äº‹å®è¡¨: ~1,000æ¡")
        print(f"   è´¢åŠ¡äº‹å®è¡¨: ~2,000æ¡")
        print("\nç°åœ¨å¯ä»¥å¼€å§‹æµ‹è¯•æ™ºèƒ½é—®æ•°ç³»ç»Ÿï¼")
        print("=" * 60 + "\n")

    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}\n")
        raise

    finally:
        initializer.postgres.close()


if __name__ == "__main__":
    main()
