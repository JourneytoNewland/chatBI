#!/usr/bin/env python3
"""æ‰¹é‡å¯¼å…¥æŒ‡æ ‡ç¤ºä¾‹è„šæœ¬.

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Management API æ‰¹é‡å¯¼å…¥æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼š
1. ç”Ÿæˆ GLM æ‘˜è¦
2. å…¥åº“åˆ° Neo4j å›¾è°±
3. å‘é‡åŒ–å¹¶å…¥åº“åˆ° Qdrant

Usage:
    # ç›´æ¥è¿è¡Œï¼ˆä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼‰
    python scripts/batch_import_metrics.py

    # æŒ‡å®š JSON æ–‡ä»¶
    python scripts/batch_import_metrics.py --file metrics.json

    # ä¸ç”Ÿæˆ GLM æ‘˜è¦ï¼ˆä»…ä½¿ç”¨æ¨¡æ¿ï¼‰
    python scripts/batch_import_metrics.py --no-summary

    # ä»…ç”Ÿæˆæ‘˜è¦ï¼Œä¸å…¥åº“
    python scripts/batch_import_metrics.py --summary-only
"""

import asyncio
import json
import time
from typing import List

import httpx
import typer


# ========== ç¤ºä¾‹æ•°æ® ==========

EXAMPLE_METRICS = [
    {
        "name": "GMV",
        "code": "gmv",
        "description": "æˆäº¤æ€»é¢ï¼ˆGross Merchandise Volumeï¼‰ï¼ŒæŒ‡åœ¨ä¸€å®šæ—¶æœŸå†…ï¼Œå¹³å°ä¸Šæ‰€æœ‰æˆäº¤è®¢å•çš„æ€»é‡‘é¢",
        "domain": "ç”µå•†",
        "synonyms": ["æˆäº¤é‡‘é¢", "äº¤æ˜“é¢", "æ€»äº¤æ˜“é¢", "é”€å”®æ€»é¢"],
        "formula": "SUM(è®¢å•é‡‘é¢)",
        "importance": 0.95
    },
    {
        "name": "DAU",
        "code": "dau",
        "description": "æ—¥æ´»è·ƒç”¨æˆ·æ•°ï¼ˆDaily Active Usersï¼‰ï¼ŒæŒ‡åœ¨ç»Ÿè®¡æ—¥å†…è‡³å°‘è®¿é—®è¿‡ä¸€æ¬¡çš„ç”¨æˆ·æ•°é‡",
        "domain": "ç”¨æˆ·",
        "synonyms": ["æ—¥æ´»", "æ—¥æ´»ç”¨æˆ·", "æ¯æ—¥æ´»è·ƒç”¨æˆ·"],
        "formula": "COUNT(DISTINCT user_id) WHERE activity_date = TODAY",
        "importance": 0.9
    },
    {
        "name": "MAU",
        "code": "mau",
        "description": "æœˆæ´»è·ƒç”¨æˆ·æ•°ï¼ˆMonthly Active Usersï¼‰ï¼ŒæŒ‡åœ¨ç»Ÿè®¡æœˆå†…è‡³å°‘è®¿é—®è¿‡ä¸€æ¬¡çš„ç”¨æˆ·æ•°é‡",
        "domain": "ç”¨æˆ·",
        "synonyms": ["æœˆæ´»", "æœˆæ´»ç”¨æˆ·", "æ¯æœˆæ´»è·ƒç”¨æˆ·"],
        "formula": "COUNT(DISTINCT user_id) WHERE activity_month = CURRENT_MONTH",
        "importance": 0.85
    },
    {
        "name": "è½¬åŒ–ç‡",
        "code": "conversion_rate",
        "description": "ç”¨æˆ·ä»æµè§ˆåˆ°è´­ä¹°çš„æ¯”ä¾‹ï¼Œç”¨äºè¡¡é‡é”€å”®æ¼æ–—çš„æ•ˆç‡",
        "domain": "è¥é”€",
        "synonyms": ["è´­ä¹°è½¬åŒ–ç‡", "æˆäº¤è½¬åŒ–ç‡"],
        "formula": "SUM(è®¢å•æ•°) / SUM(è®¿é—®UV)",
        "importance": 0.88
    },
    {
        "name": "å®¢å•ä»·",
        "code": "avg_order_value",
        "description": "å¹³å‡æ¯ç¬”è®¢å•çš„é‡‘é¢ï¼Œåæ˜ ç”¨æˆ·çš„æ¶ˆè´¹èƒ½åŠ›å’Œé”€å”®è´¨é‡",
        "domain": "ç”µå•†",
        "synonyms": ["å¹³å‡è®¢å•é‡‘é¢", "äººå‡æ¶ˆè´¹"],
        "formula": "SUM(è®¢å•é‡‘é¢) / COUNT(è®¢å•æ•°)",
        "importance": 0.8
    },
    {
        "name": "å¤è´­ç‡",
        "code": "repurchase_rate",
        "description": "åœ¨ä¸€å®šæ—¶æœŸå†…ï¼Œé‡å¤è´­ä¹°çš„ç”¨æˆ·å æ‰€æœ‰è´­ä¹°ç”¨æˆ·çš„æ¯”ä¾‹",
        "domain": "ç”¨æˆ·",
        "synonyms": ["é‡å¤è´­ä¹°ç‡", "äºŒæ¬¡è´­ä¹°ç‡"],
        "formula": "COUNT(ç”¨æˆ·è´­ä¹°æ¬¡æ•°>=2) / COUNT(DISTINCT è´­ä¹°ç”¨æˆ·)",
        "importance": 0.75
    },
    {
        "name": "ç•™å­˜ç‡",
        "code": "retention_rate",
        "description": "åœ¨æŸä¸€æ—¶é—´æ®µåï¼Œä»ç„¶æ´»è·ƒçš„ç”¨æˆ·å åˆå§‹ç”¨æˆ·æ•°çš„æ¯”ä¾‹",
        "domain": "ç”¨æˆ·",
        "synonyms": ["ç”¨æˆ·ç•™å­˜", "ç•™å­˜æ¯”ä¾‹"],
        "formula": "COUNT(DayNæ´»è·ƒç”¨æˆ·) / COUNT(Day0æ´»è·ƒç”¨æˆ·)",
        "importance": 0.82
    },
    {
        "name": "é€€è´§ç‡",
        "code": "return_rate",
        "description": "é€€è´§è®¢å•æ•°å æ€»è®¢å•æ•°çš„æ¯”ä¾‹ï¼Œç”¨äºè¡¡é‡å•†å“è´¨é‡å’Œç”¨æˆ·æ»¡æ„åº¦",
        "domain": "å”®å",
        "synonyms": ["é€€æ¬¾ç‡", "é€€è´§æ¯”ä¾‹"],
        "formula": "COUNT(é€€è´§è®¢å•) / COUNT(æ€»è®¢å•)",
        "importance": 0.7
    }
]


# ========== API å®¢æˆ·ç«¯ ==========


class MetricImportClient:
    """æŒ‡æ ‡å¯¼å…¥å®¢æˆ·ç«¯."""

    def __init__(self, base_url: str = "http://localhost:8000"):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯.

        Args:
            base_url: API åŸºç¡€ URL
        """
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=60.0)

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯."""
        await self.client.aclose()

    async def health_check(self) -> dict:
        """å¥åº·æ£€æŸ¥."""
        response = await self.client.get(f"{self.base_url}/health")
        response.raise_for_status()
        return response.json()

    async def management_health_check(self) -> dict:
        """ç®¡ç†æœåŠ¡å¥åº·æ£€æŸ¥."""
        response = await self.client.get(f"{self.base_url}/api/v1/management/health")
        response.raise_for_status()
        return response.json()

    async def batch_import(
        self,
        metrics: List[dict],
        generate_summary: bool = True,
        index_to_graph: bool = True,
        index_to_vector: bool = True,
        batch_size: int = 5
    ) -> dict:
        """æ‰¹é‡å¯¼å…¥æŒ‡æ ‡.

        Args:
            metrics: æŒ‡æ ‡åˆ—è¡¨
            generate_summary: æ˜¯å¦ç”Ÿæˆ GLM æ‘˜è¦
            index_to_graph: æ˜¯å¦å…¥åº“åˆ°å›¾è°±
            index_to_vector: æ˜¯å¦å…¥åº“åˆ°å‘é‡åº“
            batch_size: æ‰¹å¤„ç†å¤§å°

        Returns:
            å¯¼å…¥ç»“æœ
        """
        payload = {
            "metrics": metrics,
            "generate_summary": generate_summary,
            "index_to_graph": index_to_graph,
            "index_to_vector": index_to_vector,
            "batch_size": batch_size
        }

        response = await self.client.post(
            f"{self.base_url}/api/v1/management/metrics/batch-import",
            json=payload
        )
        response.raise_for_status()
        return response.json()

    async def get_task_status(self, task_id: str) -> dict:
        """è·å–ä»»åŠ¡çŠ¶æ€.

        Args:
            task_id: ä»»åŠ¡ ID

        Returns:
            ä»»åŠ¡çŠ¶æ€
        """
        response = await self.client.get(
            f"{self.base_url}/api/v1/management/tasks/{task_id}"
        )
        response.raise_for_status()
        return response.json()

    async def wait_for_task(
        self,
        task_id: str,
        poll_interval: float = 1.0,
        timeout: float = 300.0
    ) -> dict:
        """ç­‰å¾…ä»»åŠ¡å®Œæˆ.

        Args:
            task_id: ä»»åŠ¡ ID
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            æœ€ç»ˆä»»åŠ¡çŠ¶æ€
        """
        start = time.time()

        while time.time() - start < timeout:
            task_status = await self.get_task_status(task_id)

            if task_status["status"] in ["completed", "failed"]:
                return task_status

            # æ˜¾ç¤ºè¿›åº¦
            progress = task_status.get("progress", 0) * 100
            print(f"  è¿›åº¦: {progress:.1f}% - {task_status.get('message', '')}")

            await asyncio.sleep(poll_interval)

        raise TimeoutError(f"ä»»åŠ¡ {task_id} åœ¨ {timeout} ç§’åä»æœªå®Œæˆ")


# ========== ä¸»å‡½æ•° ==========


app = typer.Typer(help="æ‰¹é‡å¯¼å…¥æŒ‡æ ‡å·¥å…·")


@app.command()
def main(
    file: str = typer.Option(None, "--file", "-f", help="æŒ‡æ ‡æ•°æ® JSON æ–‡ä»¶è·¯å¾„"),
    no_summary: bool = typer.Option(False, "--no-summary", help="ä¸ç”Ÿæˆ GLM æ‘˜è¦"),
    summary_only: bool = typer.Option(False, "--summary-only", help="ä»…ç”Ÿæˆæ‘˜è¦ï¼Œä¸å…¥åº“"),
    batch_size: int = typer.Option(5, "--batch-size", "-b", help="æ‰¹å¤„ç†å¤§å°"),
    url: str = typer.Option("http://localhost:8000", "--url", "-u", help="API æœåŠ¡åœ°å€")
):
    """æ‰¹é‡å¯¼å…¥æŒ‡æ ‡åˆ°ç³»ç»Ÿ."""
    # åŠ è½½æ•°æ®
    if file:
        print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½æŒ‡æ ‡æ•°æ®: {file}")
        with open(file, "r", encoding="utf-8") as f:
            metrics = json.load(f)
    else:
        print("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹æŒ‡æ ‡æ•°æ®")
        metrics = EXAMPLE_METRICS

    print(f"âœ… å…±åŠ è½½ {len(metrics)} ä¸ªæŒ‡æ ‡")

    # è¿è¡Œå¼‚æ­¥å¯¼å…¥
    asyncio.run(import_metrics(
        metrics=metrics,
        base_url=url,
        generate_summary=not no_summary,
        index_to_graph=not summary_only,
        index_to_vector=not summary_only,
        batch_size=batch_size
    ))


async def import_metrics(
    metrics: List[dict],
    base_url: str,
    generate_summary: bool,
    index_to_graph: bool,
    index_to_vector: bool,
    batch_size: int
):
    """æ‰§è¡Œå¯¼å…¥é€»è¾‘."""
    client = MetricImportClient(base_url)

    try:
        # 1. å¥åº·æ£€æŸ¥
        print("\n1ï¸âƒ£  æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
        health = await client.health_check()
        print(f"   âœ… ä¸»æœåŠ¡: {health['status']}")

        mgmt_health = await client.management_health_check()
        print(f"   âœ… ç®¡ç†æœåŠ¡: {mgmt_health['status']}")
        print(f"   ğŸ“Š GLM æ‘˜è¦: {'âœ…' if mgmt_health['services']['glm_summary'] else 'âŒ'}")
        print(f"   ğŸ§  å›¾è°±åº“: {'âœ…' if mgmt_health['services']['graph_store'] else 'âŒ'}")
        print(f"   ğŸ” å‘é‡åº“: {'âœ…' if mgmt_health['services']['vector_store'] else 'âŒ'}")

        # 2. æ‰¹é‡å¯¼å…¥
        print("\n2ï¸âƒ£  å¼€å§‹æ‰¹é‡å¯¼å…¥...")
        print(f"   - æŒ‡æ ‡æ•°é‡: {len(metrics)}")
        print(f"   - ç”Ÿæˆæ‘˜è¦: {'æ˜¯' if generate_summary else 'å¦'}")
        print(f"   - å…¥åº“å›¾è°±: {'æ˜¯' if index_to_graph else 'å¦'}")
        print(f"   - å…¥åº“å‘é‡: {'æ˜¯' if index_to_vector else 'å¦'}")
        print(f"   - æ‰¹å¤„ç†å¤§å°: {batch_size}")

        start = time.time()
        result = await client.batch_import(
            metrics=metrics,
            generate_summary=generate_summary,
            index_to_graph=index_to_graph,
            index_to_vector=index_to_vector,
            batch_size=batch_size
        )

        task_id = result.get("task_id")
        print(f"   âœ… ä»»åŠ¡å·²æäº¤: {task_id}")

        # 3. ç­‰å¾…å®Œæˆ
        print("\n3ï¸âƒ£  ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        final_status = await client.wait_for_task(task_id)

        elapsed = time.time() - start

        # 4. æ˜¾ç¤ºç»“æœ
        print("\n4ï¸âƒ£  å¯¼å…¥ç»“æœ:")
        print(f"   - çŠ¶æ€: {final_status['status']}")
        print(f"   - æ€»æ•°: {final_status['result']['total'] if final_status['result'] else 'N/A'}")
        print(f"   - æˆåŠŸ: {final_status['result']['succeeded'] if final_status['result'] else 'N/A'}")
        print(f"   - å¤±è´¥: {final_status['result']['failed'] if final_status['result'] else 'N/A'}")
        print(f"   - è€—æ—¶: {elapsed:.2f} ç§’")

        if final_status['result'] and final_status['result'].get('errors'):
            print("\nâš ï¸  é”™è¯¯åˆ—è¡¨:")
            for error in final_status['result']['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {error}")

        print("\nâœ¨ å¯¼å…¥å®Œæˆ!")

    except httpx.HTTPError as e:
        print(f"\nâŒ HTTP è¯·æ±‚å¤±è´¥: {e}")
        raise typer.Exit(code=1)
    except Exception as e:
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {e}")
        raise typer.Exit(code=1)
    finally:
        await client.close()


# ========== å¯¼å‡ºç¤ºä¾‹æ•°æ® ==========


@app.command()
def export_example(output: str = typer.Option("metrics_example.json", "--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")):
    """å¯¼å‡ºç¤ºä¾‹æŒ‡æ ‡æ•°æ®åˆ° JSON æ–‡ä»¶."""
    with open(output, "w", encoding="utf-8") as f:
        json.dump(EXAMPLE_METRICS, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²å¯¼å‡º {len(EXAMPLE_METRICS)} ä¸ªç¤ºä¾‹æŒ‡æ ‡åˆ°: {output}")
    print(f"\nğŸ“ ç¼–è¾‘è¯¥æ–‡ä»¶åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯¼å…¥:")
    print(f"   python scripts/batch_import_metrics.py --file {output}")


if __name__ == "__main__":
    app()
