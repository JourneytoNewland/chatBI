#!/usr/bin/env python3
"""æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬.

æµ‹è¯•å‘é‡æ£€ç´¢ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡ï¼š
- å¬å›ç‡
- P99 å»¶è¿Ÿ
- QPS
- å‘é‡åŒ–é€Ÿåº¦
"""

import sys
import time
from pathlib import Path
from typing import Any

import numpy as np
from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import settings
from src.recall.vector.models import MetricMetadata
from src.recall.vector.qdrant_store import QdrantVectorStore
from src.recall.vector.vectorizer import MetricVectorizer


# æµ‹è¯•æ•°æ®
TEST_METRICS = [
    {
        "name": "GMV",
        "code": "gmv",
        "description": "æˆäº¤æ€»é¢",
        "synonyms": ["æˆäº¤é‡‘é¢", "äº¤æ˜“é¢"],
        "domain": "ç”µå•†",
    },
    {
        "name": "DAU",
        "code": "dau",
        "description": "æ—¥æ´»è·ƒç”¨æˆ·æ•°",
        "synonyms": ["æ—¥æ´»"],
        "domain": "ç”¨æˆ·",
    },
    {
        "name": "MAU",
        "code": "mau",
        "description": "æœˆæ´»è·ƒç”¨æˆ·æ•°",
        "synonyms": ["æœˆæ´»"],
        "domain": "ç”¨æˆ·",
    },
    {
        "name": "ARPU",
        "code": "arpu",
        "description": "æ¯ç”¨æˆ·å¹³å‡æ”¶å…¥",
        "synonyms": ["äººå‡æ”¶å…¥"],
        "domain": "è¥æ”¶",
    },
    {
        "name": "è½¬åŒ–ç‡",
        "code": "conversion_rate",
        "description": "è®¿å®¢è½¬åŒ–ä¸ºä»˜è´¹ç”¨æˆ·çš„æ¯”ä¾‹",
        "synonyms": ["ä»˜è´¹è½¬åŒ–ç‡"],
        "domain": "å¢é•¿",
    },
]


def benchmark_vectorization(vectorizer: MetricVectorizer, n_warmup: int = 3) -> dict[str, Any]:
    """æµ‹è¯•å‘é‡åŒ–æ€§èƒ½.

    Args:
        vectorizer: å‘é‡åŒ–å™¨å®ä¾‹
        n_warmup: é¢„çƒ­æ¬¡æ•°

    Returns:
        æ€§èƒ½æŒ‡æ ‡å­—å…¸
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š å‘é‡åŒ–æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    metrics = [MetricMetadata(**m) for m in TEST_METRICS]

    # é¢„çƒ­
    print(f"\né¢„çƒ­ {n_warmup} æ¬¡...")
    for _ in range(n_warmup):
        _ = vectorizer.vectorize_batch(metrics, show_progress=False)

    # æµ‹è¯•å•æ¡å‘é‡åŒ–
    print("\næµ‹è¯•å•æ¡å‘é‡åŒ–...")
    latencies = []
    for _ in range(10):
        start = time.time()
        _ = vectorizer.vectorize(metrics[0])
        latencies.append((time.time() - start) * 1000)

    single_avg = np.mean(latencies)
    single_p99 = np.percentile(latencies, 99)
    print(f"  å¹³å‡å»¶è¿Ÿ: {single_avg:.2f} ms")
    print(f"  P99 å»¶è¿Ÿ: {single_p99:.2f} ms")

    # æµ‹è¯•æ‰¹é‡å‘é‡åŒ–
    print("\næµ‹è¯•æ‰¹é‡å‘é‡åŒ–...")
    latencies = []
    for _ in range(10):
        start = time.time()
        _ = vectorizer.vectorize_batch(metrics, show_progress=False)
        latencies.append((time.time() - start) * 1000)

    batch_avg = np.mean(latencies)
    batch_p99 = np.percentile(latencies, 99)
    print(f"  å¹³å‡å»¶è¿Ÿ: {batch_avg:.2f} ms")
    print(f"  P99 å»¶è¿Ÿ: {batch_p99:.2f} ms")
    print(f"  å¹³å‡æ¯æ¡: {batch_avg / len(metrics):.2f} ms")

    return {
        "single_avg_ms": single_avg,
        "single_p99_ms": single_p99,
        "batch_avg_ms": batch_avg,
        "batch_p99_ms": batch_p99,
        "batch_per_item_ms": batch_avg / len(metrics),
    }


def benchmark_search(
    vectorizer: MetricVectorizer,
    vector_store: QdrantVectorStore,
    n_queries: int = 100,
) -> dict[str, Any]:
    """æµ‹è¯•æ£€ç´¢æ€§èƒ½.

    Args:
        vectorizer: å‘é‡åŒ–å™¨å®ä¾‹
        vector_store: å‘é‡å­˜å‚¨å®ä¾‹
        n_queries: æŸ¥è¯¢æ¬¡æ•°

    Returns:
        æ€§èƒ½æŒ‡æ ‡å­—å…¸
    """
    print("\n" + "=" * 60)
    print("ğŸ” æ£€ç´¢æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    # å‡†å¤‡æŸ¥è¯¢
    query = "æˆäº¤æ€»é¢"
    query_metadata = MetricMetadata(
        name=query,
        code=query,
        description=query,
        synonyms=[],
        domain="æŸ¥è¯¢",
    )
    query_vector = vectorizer.vectorize(query_metadata)

    # é¢„çƒ­
    print(f"\né¢„çƒ­ 10 æ¬¡...")
    for _ in range(10):
        _ = vector_store.search(query_vector, top_k=10)

    # æµ‹è¯•æ£€ç´¢å»¶è¿Ÿ
    print(f"\næ‰§è¡Œ {n_queries} æ¬¡æŸ¥è¯¢...")
    latencies = []
    for _ in range(n_queries):
        start = time.time()
        _ = vector_store.search(query_vector, top_k=10)
        latencies.append((time.time() - start) * 1000)

    avg_latency = np.mean(latencies)
    p50_latency = np.percentile(latencies, 50)
    p95_latency = np.percentile(latencies, 95)
    p99_latency = np.percentile(latencies, 99)
    min_latency = np.min(latencies)
    max_latency = np.max(latencies)

    print(f"\nå»¶è¿Ÿç»Ÿè®¡:")
    print(f"  å¹³å‡: {avg_latency:.2f} ms")
    print(f"  P50: {p50_latency:.2f} ms")
    print(f"  P95: {p95_latency:.2f} ms")
    print(f"  P99: {p99_latency:.2f} ms")
    print(f"  æœ€å°: {min_latency:.2f} ms")
    print(f"  æœ€å¤§: {max_latency:.2f} ms")

    # è®¡ç®— QPS
    qps = 1000 / avg_latency
    print(f"\nQPS: {qps:.2f}")

    return {
        "avg_ms": avg_latency,
        "p50_ms": p50_latency,
        "p95_ms": p95_latency,
        "p99_ms": p99_latency,
        "min_ms": min_latency,
        "max_ms": max_latency,
        "qps": qps,
    }


def benchmark_recall(
    vectorizer: MetricVectorizer,
    vector_store: QdrantVectorStore,
) -> dict[str, Any]:
    """æµ‹è¯•å¬å›ç‡.

    Args:
        vectorizer: å‘é‡åŒ–å™¨å®ä¾‹
        vector_store: å‘é‡å­˜å‚¨å®ä¾‹

    Returns:
        å¬å›ç‡æŒ‡æ ‡
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ å¬å›ç‡æµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•æŸ¥è¯¢
    test_cases = [
        {
            "query": "GMV",
            "expected": "GMV",
            "description": "ç²¾ç¡®åŒ¹é…",
        },
        {
            "query": "æˆäº¤æ€»é¢",
            "expected": "GMV",
            "description": "åŒä¹‰è¯æŸ¥è¯¢",
        },
        {
            "query": "æ—¥æ´»ç”¨æˆ·",
            "expected": "DAU",
            "description": "åŒä¹‰å˜ä½“",
        },
    ]

    recall_results = []

    for case in test_cases:
        query = case["query"]
        expected = case["expected"]
        description = case["description"]

        # å‘é‡åŒ–æŸ¥è¯¢
        query_metadata = MetricMetadata(
            name=query,
            code=query,
            description=query,
            synonyms=[],
            domain="æŸ¥è¯¢",
        )
        query_vector = vectorizer.vectorize(query_metadata)

        # æ£€ç´¢
        results = vector_store.search(query_vector, top_k=5)

        # æ£€æŸ¥é¢„æœŸç»“æœæ˜¯å¦åœ¨ Top-K ä¸­
        found = any(r["payload"]["name"] == expected for r in results)
        rank = next((i + 1 for i, r in enumerate(results) if r["payload"]["name"] == expected), None)

        print(f"\n{description}: '{query}' -> '{expected}'")
        print(f"  æ‰¾åˆ°: {'âœ“' if found else 'âœ—'}")
        if found and rank:
            print(f"  æ’å: {rank}")

        recall_results.append(
            {
                "query": query,
                "expected": expected,
                "found": found,
                "rank": rank,
                "description": description,
            }
        )

    # è®¡ç®—å¬å›ç‡
    recall_rate = sum(1 for r in recall_results if r["found"]) / len(recall_results)
    print(f"\næ€»ä½“å¬å›ç‡: {recall_rate * 100:.1f}%")

    return {
        "recall_rate": recall_rate,
        "details": recall_results,
    }


def main() -> None:
    """ä¸»å‡½æ•°."""
    print("=" * 60)
    print("ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)

    # 1. åˆå§‹åŒ–
    print("\n[1/4] åˆå§‹åŒ–ç»„ä»¶...")
    vectorizer = MetricVectorizer(model_name=settings.vectorizer.model_name)
    print(f"  âœ“ å‘é‡åŒ–å™¨: {settings.vectorizer.model_name}")

    # ä½¿ç”¨å†…å­˜æ¨¡å¼ Qdrant
    client = QdrantClient(":memory:")
    client.create_collection(
        collection_name="benchmark",
        vectors_config=VectorParams(size=768, distance=Distance.COSINE),
    )

    config = settings.qdrant
    config.collection_name = "benchmark"
    vector_store = QdrantVectorStore(config=config)
    vector_store.client = client
    print(f"  âœ“ å‘é‡å­˜å‚¨: {config.collection_name}")

    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\n[2/4] å‡†å¤‡æµ‹è¯•æ•°æ®...")
    metrics = [MetricMetadata(**m) for m in TEST_METRICS]
    embeddings = vectorizer.vectorize_batch(metrics, show_progress=False)

    metric_ids = [f"m{i:03d}" for i in range(len(metrics))]
    payloads = [
        {
            "metric_id": mid,
            "name": m.name,
            "code": m.code,
            "description": m.description,
            "synonyms": m.synonyms,
            "domain": m.domain,
        }
        for mid, m in zip(metric_ids, metrics)
    ]

    vector_store.upsert(metric_ids, embeddings, payloads)
    print(f"  âœ“ æ’å…¥ {len(metrics)} æ¡æµ‹è¯•æ•°æ®")

    # 3. è¿è¡Œæ€§èƒ½æµ‹è¯•
    vectorization_results = benchmark_vectorization(vectorizer)
    search_results = benchmark_search(vectorizer, vector_store)
    recall_results = benchmark_recall(vectorizer, vector_store)

    # 4. æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ€§èƒ½æµ‹è¯•æ±‡æ€»")
    print("=" * 60)

    print("\nå‘é‡åŒ–æ€§èƒ½:")
    print(f"  å•æ¡å»¶è¿Ÿ: {vectorization_results['single_avg_ms']:.2f} ms (P99: {vectorization_results['single_p99_ms']:.2f} ms)")
    print(f"  æ‰¹é‡å»¶è¿Ÿ: {vectorization_results['batch_avg_ms']:.2f} ms (P99: {vectorization_results['batch_p99_ms']:.2f} ms)")

    print("\næ£€ç´¢æ€§èƒ½:")
    print(f"  å¹³å‡å»¶è¿Ÿ: {search_results['avg_ms']:.2f} ms")
    print(f"  P95 å»¶è¿Ÿ: {search_results['p95_ms']:.2f} ms")
    print(f"  P99 å»¶è¿Ÿ: {search_results['p99_ms']:.2f} ms")
    print(f"  QPS: {search_results['qps']:.2f}")

    print("\nå¬å›ç‡:")
    print(f"  æ€»ä½“å¬å›ç‡: {recall_results['recall_rate'] * 100:.1f}%")

    # éªŒè¯ç›®æ ‡
    print("\n" + "=" * 60)
    print("ğŸ¯ ç›®æ ‡éªŒè¯")
    print("=" * 60)

    target_p99 = 50.0  # ms
    target_recall = 0.85  # 85%

    p99_passed = search_results["p99_ms"] <= target_p99
    recall_passed = recall_results["recall_rate"] >= target_recall

    print(f"\nP99 å»¶è¿Ÿ â‰¤ {target_p99} ms: {'âœ“ é€šè¿‡' if p99_passed else 'âœ— æœªé€šè¿‡'} ({search_results['p99_ms']:.2f} ms)")
    print(f"å¬å›ç‡ â‰¥ {target_recall * 100}%: {'âœ“ é€šè¿‡' if recall_passed else 'âœ— æœªé€šè¿‡'} ({recall_results['recall_rate'] * 100:.1f}%)")

    all_passed = p99_passed and recall_passed
    print(f"\næ€»ä½“ç»“æœ: {'âœ“ å…¨éƒ¨é€šè¿‡' if all_passed else 'âœ— éƒ¨åˆ†æœªé€šè¿‡'}")

    print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
