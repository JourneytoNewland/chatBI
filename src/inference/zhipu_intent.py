"""æ™ºè°±AI GLMæ„å›¾è¯†åˆ«æ¨¡å—."""

import json
import os
import time
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Optional

import httpx


@dataclass
class ZhipuIntentResult:
    """æ™ºè°±æ„å›¾è¯†åˆ«ç»“æœ."""

    core_query: str
    time_range: Optional[dict[str, str]]
    time_granularity: Optional[str]
    aggregation_type: Optional[str]
    dimensions: list[str]
    comparison_type: Optional[str]
    filters: dict[str, Any]
    confidence: float
    reasoning: str
    model: str
    latency: float
    tokens_used: dict[str, int]


class ZhipuIntentRecognizer:
    """åŸºäºæ™ºè°±AI GLMçš„æ„å›¾è¯†åˆ«å™¨.

    ä¼˜åŠ¿:
    - å›½äº§æ¨¡å‹ï¼Œæ— éœ€VPN
    - ä»·æ ¼ä¼˜æƒ ï¼ˆÂ¥1/1M tokensï¼‰
    - æ”¯æŒä¸­æ–‡ä¼˜åŒ–
    - é«˜é€Ÿç‡é™åˆ¶ï¼ˆTPM/RPMé«˜ï¼‰
    """

    # APIé…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œä¸ä½¿ç”¨ç¡¬ç¼–ç å¯†é’¥
    API_KEY = os.getenv("ZHIPUAI_API_KEY")
    if not API_KEY:
        raise ValueError("ZHIPUAI_API_KEY environment variable is required")
    BASE_URL = "https://open.bigmodel.cn/api/paas/v4"

    # æ¨¡å‹é€‰æ‹©
    MODEL_FAST = "glm-4-flash"  # å¿«é€Ÿæ¨¡å‹ï¼Œå…è´¹
    MODEL_STANDARD = "glm-4-plus"  # æ ‡å‡†æ¨¡å‹
    MODEL_PREMIUM = "glm-4-0520"  # æœ€æ–°æ¨¡å‹

    # Few-shotç¤ºä¾‹
    FEW_SHOT_EXAMPLES = [
        {
            "query": "GMV",
            "intent": {
                "core_query": "GMV",
                "time_range": None,
                "time_granularity": None,
                "aggregation_type": None,
                "dimensions": [],
                "comparison_type": None,
                "filters": {},
                "confidence": 1.0,
                "reasoning": "ç²¾ç¡®æŒ‡æ ‡åç§°æŸ¥è¯¢"
            }
        },
        {
            "query": "æœ€è¿‘7å¤©çš„GMV",
            "intent": {
                "core_query": "GMV",
                "time_range": {
                    "type": "relative",
                    "value": "7d",
                    "description": "æœ€è¿‘7å¤©"
                },
                "time_granularity": "day",
                "aggregation_type": None,
                "dimensions": [],
                "comparison_type": None,
                "filters": {},
                "confidence": 0.98,
                "reasoning": "è¯†åˆ«åˆ°æ—¶é—´è¯'æœ€è¿‘7å¤©'ï¼ˆç›¸å¯¹æ—¶é—´ï¼‰ï¼Œæ ¸å¿ƒæŒ‡æ ‡ä¸ºGMV"
            }
        },
        {
            "query": "æœ¬æœˆæŒ‰æ¸ é“ç»Ÿè®¡DAU",
            "intent": {
                "core_query": "DAU",
                "time_range": {
                    "type": "absolute",
                    "value": "this_month",
                    "description": "æœ¬æœˆ"
                },
                "time_granularity": "month",
                "aggregation_type": None,
                "dimensions": ["æ¸ é“"],
                "comparison_type": None,
                "filters": {},
                "confidence": 0.95,
                "reasoning": "è¯†åˆ«åˆ°æ—¶é—´è¯'æœ¬æœˆ'ï¼Œç»´åº¦è¯'æŒ‰æ¸ é“'æå–ä¸ºdimensions=['æ¸ é“']ï¼Œæ ¸å¿ƒæŒ‡æ ‡ä¸º'DAU'ï¼ˆå»é™¤'æŒ‰æ¸ é“ç»Ÿè®¡'ï¼‰"
            }
        },
        {
            "query": "æŒ‰åœ°åŒºçš„æˆäº¤é‡‘é¢åŒæ¯”",
            "intent": {
                "core_query": "æˆäº¤é‡‘é¢",
                "time_range": None,
                "time_granularity": None,
                "aggregation_type": None,
                "dimensions": ["åœ°åŒº"],
                "comparison_type": "yoy",
                "filters": {},
                "confidence": 0.92,
                "reasoning": "è¯†åˆ«åˆ°ç»´åº¦'æŒ‰åœ°åŒº'ï¼Œæ¯”è¾ƒè¯'åŒæ¯”'ï¼ˆyear-over-yearï¼‰ï¼Œæ ¸å¿ƒæŸ¥è¯¢'æˆäº¤é‡‘é¢'æ˜¯GMVçš„åŒä¹‰è¯"
            }
        },
        {
            "query": "2024å¹´1æœˆçš„è®¢å•è½¬åŒ–ç‡",
            "intent": {
                "core_query": "conversion_rate",
                "time_range": {
                    "type": "absolute",
                    "value": "2024-01",
                    "description": "2024å¹´1æœˆ"
                },
                "time_granularity": "month",
                "aggregation_type": None,
                "dimensions": [],
                "comparison_type": None,
                "filters": {},
                "confidence": 0.93,
                "reasoning": "è¯†åˆ«åˆ°ç²¾ç¡®æ—¶é—´'2024å¹´1æœˆ'ï¼Œæ ¸å¿ƒæŸ¥è¯¢'è®¢å•è½¬åŒ–ç‡'æ˜ å°„åˆ°conversion_rateæŒ‡æ ‡"
            }
        },
    ]

    def __init__(self, model: str = MODEL_FAST):
        """åˆå§‹åŒ–æ™ºè°±æ„å›¾è¯†åˆ«å™¨.

        Args:
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.model = model
        self.api_key = self.API_KEY

        if not self.api_key:
            print("âš ï¸  è­¦å‘Š: ZHIPUAI_API_KEY æœªè®¾ç½®")
            print("   è®¾ç½®æ–¹æ³•: export ZHIPUAI_API_KEY='your-api-key'")

    def _build_prompt(self, query: str, candidates: list = None) -> str:
        """æ„å»ºFew-shotæç¤ºè¯."""
        examples_text = ""
        for i, example in enumerate(self.FEW_SHOT_EXAMPLES[:4], 1):
            examples_text += f"""
### ç¤ºä¾‹ {i}
æŸ¥è¯¢: {example['query']}
æ„å›¾: {json.dumps(example['intent'], ensure_ascii=False, indent=2)}

"""

        # æ·»åŠ å¯ç”¨æŒ‡æ ‡åˆ—è¡¨
        candidates_info = ""
        if candidates:
            candidate_names = [c.get('name', c.get('metric_id', '')) for c in candidates[:20]]
            candidates_info = f"""
## å¯ç”¨æŒ‡æ ‡åˆ—è¡¨
{json.dumps(candidate_names, ensure_ascii=False, indent=2)}

é‡è¦ï¼šcore_query å¿…é¡»ä»ä¸Šè¿°æŒ‡æ ‡åˆ—è¡¨ä¸­é€‰æ‹©ï¼å¦‚æœæŸ¥è¯¢è¯ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œè¯·é€‰æ‹©æœ€ç›¸ä¼¼çš„æŒ‡æ ‡ã€‚
"""

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„BIï¼ˆå•†ä¸šæ™ºèƒ½ï¼‰æŸ¥è¯¢æ„å›¾è¯†åˆ«ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæå–ç»“æ„åŒ–çš„æ„å›¾ä¿¡æ¯ã€‚

## æ ¸å¿ƒè§„åˆ™

1. **core_queryæå–**ï¼ˆæœ€é‡è¦ï¼‰ï¼š
   - å»é™¤æ—¶é—´è¯ï¼šæœ€è¿‘ã€æœ¬æœˆã€2024å¹´1æœˆã€æœ¬å‘¨ç­‰
   - å»é™¤ç»´åº¦å‰ç¼€ï¼šæŒ‰XXç»Ÿè®¡ã€æŒ‰XXåˆ†æã€æŒ‰XXæŸ¥çœ‹ã€æŒ‰XXçœ‹ â†’ æå–"XX"åˆ°dimensionsï¼Œå‰©ä½™éƒ¨åˆ†ä¸ºcore_query
   - å»é™¤ç»Ÿè®¡è¯ï¼šç»Ÿè®¡ã€åˆ†æã€æŸ¥çœ‹ã€å±•ç¤ºã€æ˜¾ç¤ºç­‰
   - å»é™¤ç–‘é—®è¯ï¼šæ˜¯ä»€ä¹ˆã€å¤šå°‘ã€å¦‚ä½•ç­‰
   - ä¿ç•™æ ¸å¿ƒæŒ‡æ ‡åç§°ï¼ˆå¿…é¡»ä»å¯ç”¨æŒ‡æ ‡åˆ—è¡¨é€‰æ‹©ï¼‰
   - åŒä¹‰è¯æ˜ å°„ï¼šæˆäº¤é‡‘é¢â†’GMVã€æˆäº¤æ€»é¢â†’GMVã€è®¢å•è½¬åŒ–ç‡â†’conversion_rate

2. **ç»´åº¦æå–**ï¼š
   - "æŒ‰æ¸ é“ç»Ÿè®¡"ã€"æŒ‰æ¸ é“åˆ†æ"ã€"æŒ‰æ¸ é“æŸ¥çœ‹" â†’ dimensions=["æ¸ é“"]
   - "æŒ‰åœ°åŒº"ã€"æŒ‰å“ç±»"ã€"æŒ‰ç”¨æˆ·ç­‰çº§" â†’ dimensionsæå–å¯¹åº”ç»´åº¦
   - å…³é”®ç¤ºä¾‹ï¼š
     * "æœ¬æœˆæŒ‰æ¸ é“ç»Ÿè®¡DAU" â†’ core_query="DAU", dimensions=["æ¸ é“"]
     * "æŒ‰åœ°åŒºçš„æˆäº¤é‡‘é¢" â†’ core_query="GMV", dimensions=["åœ°åŒº"]

3. **èšåˆè¯è¯†åˆ«**ï¼š
   - "æ€»å’Œ"ã€"æ€»è®¡"ã€"åˆè®¡" â†’ aggregation_type="sum"
   - "å¹³å‡"ã€"å‡å€¼"ã€"å¹³å‡æ•°" â†’ aggregation_type="avg"
   - "ç»Ÿè®¡"ã€"åˆ†æ"ã€"æŸ¥çœ‹"ï¼ˆæ— æ˜ç¡®èšåˆè¯ï¼‰ â†’ aggregation_type=null

4. **åŒä¹‰è¯æ˜ å°„**ï¼š
   - "æˆäº¤é‡‘é¢"ã€"äº¤æ˜“é¢"ã€"æˆäº¤æ€»é¢"ã€"é”€å”®é¢"ã€"æµæ°´" â†’ GMV
   - "è®¢å•è½¬åŒ–ç‡"ã€"è½¬åŒ–ç‡"ã€"è½¬åŒ–æ¯”ç‡" â†’ conversion_rate
   - "æ—¥æ´»ç”¨æˆ·"ã€"æ¯æ—¥æ´»è·ƒç”¨æˆ·" â†’ DAU

## æ„å›¾ç»´åº¦è¯´æ˜

è¯·ä»ä»¥ä¸‹7ä¸ªç»´åº¦åˆ†ææŸ¥è¯¢ï¼š

1. **core_query**: æ ¸å¿ƒæŒ‡æ ‡åï¼ˆå¿…é¡»ä»å¯ç”¨æŒ‡æ ‡åˆ—è¡¨é€‰æ‹©ï¼‰
2. **time_range**: æ—¶é—´èŒƒå›´ï¼ˆç›¸å¯¹æ—¶é—´æˆ–ç»å¯¹æ—¶é—´ï¼‰
3. **time_granularity**: day/week/month/quarter/year
4. **aggregation_type**: sum/avg/count/max/min/rate/ratio
5. **dimensions**: ç»´åº¦åˆ—è¡¨ï¼Œå¦‚["åœ°åŒº", "å“ç±»"]
6. **comparison_type**: yoy(åŒæ¯”)/mom(ç¯æ¯”)/dod(æ—¥ç¯æ¯”)/wow(å‘¨ç¯æ¯”)
7. **filters**: è¿‡æ»¤æ¡ä»¶ï¼Œå¦‚{{"domain": "ç”µå•†"}}

## è¾“å‡ºæ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼š
```json
{{
    "core_query": "æ ¸å¿ƒæŒ‡æ ‡å",
    "time_range": null or {{"type": "...", "value": "...", "description": "..."}},
    "time_granularity": null or "day|week|month|quarter|year",
    "aggregation_type": null or "sum|avg|count|max|min|rate|ratio",
    "dimensions": [],
    "comparison_type": null or "yoy|mom|dod|wow",
    "filters": {{}},
    "confidence": 0.95,
    "reasoning": "è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹"
}}
```
{candidates_info}
## Few-Shotç¤ºä¾‹
{examples_text}
## å¾…è¯†åˆ«æŸ¥è¯¢

æŸ¥è¯¢: {query}

è¯·åˆ†æä¸Šè¿°æŸ¥è¯¢å¹¶è¾“å‡ºJSONæ ¼å¼çš„æ„å›¾ä¿¡æ¯ï¼ˆåªè¾“å‡ºJSONï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ï¼‰ï¼š
"""
        return prompt

    def generate_response(self, prompt: str, system_prompt: str = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ã€‚") -> Optional[str]:
        """è°ƒç”¨æ™ºè°±APIç”Ÿæˆå“åº”.

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯

        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if not self.api_key:
            print("âŒ æ™ºè°±APIå¯†é’¥æœªé…ç½®")
            return None

        try:
            # æ„å»ºJWT token
            token = self._generate_token()

            # è°ƒç”¨æ™ºè°±API
            with httpx.Client(timeout=60.0) as client:
                response = client.post(
                    f"{self.BASE_URL}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {token}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {
                                "role": "system",
                                "content": system_prompt
                            },
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        "temperature": 0.1,
                        "top_p": 0.7,
                        "max_tokens": 1000,
                    }
                )

                response.raise_for_status()
                data = response.json()

            # è§£æç»“æœ
            content = data["choices"][0]["message"]["content"]
            return content

        except Exception as e:
            print(f"âŒ æ™ºè°±APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def recognize(self, query: str, candidates: list = None) -> Optional[ZhipuIntentResult]:
        """è¯†åˆ«æŸ¥è¯¢æ„å›¾.

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            candidates: å€™é€‰æŒ‡æ ‡åˆ—è¡¨ï¼ˆä»å‘é‡æ£€ç´¢è·å–ï¼‰

        Returns:
            æ™ºè°±æ„å›¾è¯†åˆ«ç»“æœ
        """
        start_time = time.time()

        try:
            # æ„å»ºPrompt
            prompt = self._build_prompt(query, candidates)
            
            # è°ƒç”¨LLM
            content = self.generate_response(
                prompt, 
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„BIæŸ¥è¯¢æ„å›¾è¯†åˆ«ä¸“å®¶ã€‚ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–å†…å®¹ã€‚"
            )
            
            if not content:
                return None

            # æ¸…ç†å¯èƒ½çš„markdownæ ‡è®°
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()

            intent_data = json.loads(content)

            # æ„å»ºç»“æœ
            return ZhipuIntentResult(
                core_query=intent_data.get("core_query", query),
                time_range=intent_data.get("time_range"),
                time_granularity=intent_data.get("time_granularity"),
                aggregation_type=intent_data.get("aggregation_type"),
                dimensions=intent_data.get("dimensions", []),
                comparison_type=intent_data.get("comparison_type"),
                filters=intent_data.get("filters", {}),
                confidence=intent_data.get("confidence", 0.8),
                reasoning=intent_data.get("reasoning", ""),
                model=self.model,
                latency=time.time() - start_time,
                tokens_used={"total_tokens": 0} # ç®€åŒ–ï¼Œå¦‚æœéœ€è¦ç²¾ç¡®ç»Ÿè®¡éœ€é‡æ„è¿”å›å€¼
            )

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"   åŸå§‹å“åº”: {content if 'content' in locals() else 'N/A'}")
            return None
        except Exception as e:
            print(f"âŒ æ™ºè°±æ„å›¾è¯†åˆ«å¼‚å¸¸: {e}")
            return None

    def _generate_token(self) -> str:
        """ç”Ÿæˆæ™ºè°±APIçš„JWT token."""
        import hmac
        import hashlib
        import base64
        import time

        try:
            # åˆ†ç¦»APIå¯†é’¥
            if "." not in self.api_key:
                raise ValueError("API Keyæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º id.secret")

            api_id, api_secret = self.api_key.split(".", 1)

            # æ„é€ JWT payload
            now = int(time.time())
            payload = {
                "api_key": api_id,
                "exp": now + 3600,  # 1å°æ—¶è¿‡æœŸ
                "timestamp": now
            }

            # ç¼–ç headerå’Œpayload
            header = {"alg": "HS256", "sign_type": "SIGN"}

            header_b64 = base64.urlsafe_b64encode(
                json.dumps(header, separators=(',', ':')).encode()
            ).decode().rstrip('=')

            payload_b64 = base64.urlsafe_b64encode(
                json.dumps(payload, separators=(',', ':')).encode()
            ).decode().rstrip('=')

            # ç”Ÿæˆç­¾å
            message = f"{header_b64}.{payload_b64}"
            signature = hmac.new(
                api_secret.encode(),
                message.encode(),
                hashlib.sha256
            ).digest()

            signature_b64 = base64.urlsafe_b64encode(signature).decode().rstrip('=')

            # ç»„åˆJWT
            token = f"{header_b64}.{payload_b64}.{signature_b64}"
            return token

        except Exception as e:
            print(f"âŒ Tokenç”Ÿæˆå¤±è´¥: {e}")
            raise


# æµ‹è¯•å‡½æ•°
def test_zhipu_recognizer():
    """æµ‹è¯•æ™ºè°±æ„å›¾è¯†åˆ«å™¨."""
    print("\nğŸ§ª æµ‹è¯•æ™ºè°±AIæ„å›¾è¯†åˆ«")
    print("=" * 50)

    recognizer = ZhipuIntentRecognizer(model="glm-4-flash")

    test_queries = [
        "GMVæ˜¯ä»€ä¹ˆ",
        "æœ€è¿‘7å¤©çš„æˆäº¤é‡‘é¢",
        "æœ¬æœˆè¥æ”¶æ€»å’Œ",
        "æŒ‰åœ°åŒºçš„DAUåŒæ¯”"
    ]

    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        print("-" * 50)

        result = recognizer.recognize(query)

        if result:
            print(f"âœ… è¯†åˆ«æˆåŠŸ")
            print(f"   æ ¸å¿ƒæŸ¥è¯¢: {result.core_query}")
            print(f"   ç½®ä¿¡åº¦: {result.confidence}")
            print(f"   è€—æ—¶: {result.latency*1000:.2f}ms")
            print(f"   Tokens: {result.tokens_used['total_tokens']}")
            print(f"   æ¨ç†: {result.reasoning}")
        else:
            print(f"âŒ è¯†åˆ«å¤±è´¥")

    print("\n" + "=" * 50)


if __name__ == "__main__":
    test_zhipu_recognizer()
