"""BGE-M3åµŒå…¥æ¨¡å‹å‡çº§æ¨¡å—."""

import os
from typing import List, Union

import numpy as np


class BGEEmbeddingModel:
    """BGE-M3å¤šè¯­è¨€åµŒå…¥æ¨¡å‹.

    ä¼˜åŠ¿:
    - æ”¯æŒä¸­æ–‡ä¼˜åŒ–
    - 8192ç»´å‘é‡ï¼ˆé«˜ç²¾åº¦ï¼‰
    - æ”¯æŒé•¿æ–‡æœ¬ï¼ˆ8192 tokensï¼‰
    - å¤šåŠŸèƒ½ï¼ˆæ£€ç´¢ã€é‡æ’åºã€åˆ†ç±»ï¼‰

    æ¨¡å‹: BAAI/bge-m3
    """

    def __init__(self, model_name: str = "BAAI/bge-m3", device: str = "cpu"):
        """åˆå§‹åŒ–BGEåµŒå…¥æ¨¡å‹.

        Args:
            model_name: æ¨¡å‹åç§°
            device: è¿è¡Œè®¾å¤‡ï¼ˆcpu/cuda/mpsï¼‰
        """
        self.model_name = model_name
        self.device = device
        self.model = None
        self.dimension = 1024  # BGE-M3é»˜è®¤1024ç»´

        # å»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶é—´è¿‡é•¿
        self._lazy_loaded = False

    def _load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹."""
        if self._lazy_loaded:
            return

        try:
            from sentence_transformers import SentenceTransformer

            print(f"ğŸ“¦ åŠ è½½BGE-M3æ¨¡å‹ ({self.model_name})...")

            # æ£€æµ‹MPSï¼ˆApple Silicon GPUï¼‰
            if self.device == "auto":
                import torch
                if torch.backends.mps.is_available():
                    self.device = "mps"
                elif torch.cuda.is_available():
                    self.device = "cuda"
                else:
                    self.device = "cpu"

            # åŠ è½½æ¨¡å‹
            self.model = SentenceTransformer(
                self.model_name,
                device=self.device
            )

            self._lazy_loaded = True
            print(f"âœ… BGE-M3æ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {self.device})")

        except ImportError:
            print("âŒ sentence-transformersæœªå®‰è£…")
            print("   å®‰è£…: pip install sentence-transformers")
            raise
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def encode(
        self,
        texts: Union[str, list[str]],
        normalize: bool = True,
        show_progress: bool = False
    ) -> Union[list[float], list[list[float]]]:
        """ç¼–ç æ–‡æœ¬ä¸ºå‘é‡.

        Args:
            texts: å•ä¸ªæ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
            normalize: æ˜¯å¦å½’ä¸€åŒ–
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            å‘é‡æˆ–å‘é‡åˆ—è¡¨
        """
        self._load_model()

        # å•ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºåˆ—è¡¨
        single_input = isinstance(texts, str)
        if single_input:
            texts = [texts]

        # ç¼–ç 
        embeddings = self.model.encode(
            texts,
            normalize_embeddings=normalize,
            show_progress_bar=show_progress,
            convert_to_numpy=True
        )

        # è½¬æ¢ä¸ºåˆ—è¡¨
        if single_input:
            return embeddings[0].tolist()
        else:
            return [emb.tolist() for emb in embeddings]

    def encode_query(self, query: str) -> List[float]:
        """ç¼–ç æŸ¥è¯¢æ–‡æœ¬ï¼ˆæ·»åŠ æŒ‡ä»¤å‰ç¼€ï¼‰.

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            å‘é‡è¡¨ç¤º
        """
        # BGE-M3ä¸ºæŸ¥è¯¢æ·»åŠ æŒ‡ä»¤å‰ç¼€
        instruction = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š"
        query_with_instruction = f"{instruction}{query}"

        return self.encode(query_with_instruction)

    def compute_similarity(
        self,
        query_embedding: List[float],
        document_embeddings: List[List[float]]
    ) -> List[float]:
        """è®¡ç®—æŸ¥è¯¢ä¸æ–‡æ¡£çš„ç›¸ä¼¼åº¦.

        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            document_embeddings: æ–‡æ¡£å‘é‡åˆ—è¡¨

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨
        """
        query_vec = np.array(query_embedding)
        doc_vecs = np.array(document_embeddings)

        # ç‚¹ç§¯ï¼ˆå‘é‡å·²å½’ä¸€åŒ–ï¼Œç­‰ä»·äºcosineç›¸ä¼¼åº¦ï¼‰
        similarities = np.dot(doc_vecs, query_vec)

        return similarities.tolist()

    def get_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦."""
        return self.dimension

    def is_available(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨."""
        try:
            self._load_model()
            return True
        except Exception:
            return False


class OpenAIEmbeddingModel:
    """OpenAIåµŒå…¥æ¨¡å‹ï¼ˆäº‘ç«¯æ–¹æ¡ˆï¼‰.

    ä¼˜åŠ¿:
    - æœ€é«˜ç²¾åº¦ï¼ˆ3072ç»´ï¼‰
    - æ— éœ€æœ¬åœ°èµ„æº
    - APIç¨³å®šå¯é 

    åŠ£åŠ¿:
    - éœ€è¦ä»˜è´¹
    - æ•°æ®éœ€ä¸Šä¼ äº‘ç«¯
    """

    def __init__(self, api_key: str = None, model: str = "text-embedding-3-large"):
        """åˆå§‹åŒ–OpenAIåµŒå…¥æ¨¡å‹.

        Args:
            api_key: OpenAI APIå¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model = model
        self.dimension = 3072 if "large" in model else 1536

    def encode(self, texts: Union[str, List[str]]) -> Union[List[float], List[List[float]]]:
        """ç¼–ç æ–‡æœ¬ä¸ºå‘é‡."""
        if not self.api_key:
            raise ValueError("OpenAI APIå¯†é’¥æœªè®¾ç½®")

        import openai

        client = openai.OpenAI(api_key=self.api_key)

        single_input = isinstance(texts, str)
        if single_input:
            texts = [texts]

        response = client.embeddings.create(
            model=self.model,
            input=texts
        )

        embeddings = [item.embedding for item in response.data]

        if single_input:
            return embeddings[0]
        else:
            return embeddings

    def is_available(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨."""
        return bool(self.api_key)


# å…¨å±€æ¨¡å‹å®ä¾‹
_bge_model = None

def get_bge_model() -> BGEEmbeddingModel:
    """è·å–BGEæ¨¡å‹å•ä¾‹."""
    global _bge_model
    if _bge_model is None:
        _bge_model = BGEEmbeddingModel(device="auto")
    return _bge_model


# æµ‹è¯•å‡½æ•°
def test_bge_embedding():
    """æµ‹è¯•BGEåµŒå…¥æ¨¡å‹."""
    print("\nğŸ§ª æµ‹è¯•BGE-M3åµŒå…¥æ¨¡å‹")
    print("=" * 50)

    try:
        model = BGEEmbeddingModel(device="auto")

        # æµ‹è¯•æ–‡æœ¬
        texts = [
            "GMVæ˜¯ä»€ä¹ˆ",
            "æœ€è¿‘7å¤©çš„æˆäº¤é‡‘é¢",
            "æœ¬æœˆè¥æ”¶æ€»å’Œ"
        ]

        print(f"\nç¼–ç  {len(texts)} ä¸ªæ–‡æœ¬...")
        embeddings = model.encode(texts, show_progress=True)

        print(f"âœ… ç¼–ç æˆåŠŸ")
        print(f"   å‘é‡ç»´åº¦: {len(embeddings[0])}")
        print(f"   å‘é‡æ•°é‡: {len(embeddings)}")

        # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
        query = "GMV"
        query_emb = model.encode_query(query)

        similarities = model.compute_similarity(query_emb, embeddings)

        print(f"\næŸ¥è¯¢: {query}")
        print("-" * 50)
        for text, sim in zip(texts, similarities):
            print(f"   {text}: {sim:.4f}")

        print("\n" + "=" * 50)

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    test_bge_embedding()
