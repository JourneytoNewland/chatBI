"""åˆå§‹åŒ–PostgreSQLæµ‹è¯•æ•°æ®."""

import logging
import random
from datetime import datetime, timedelta
from typing import List

from src.database.postgres_client import postgres_client


logger = logging.getLogger(__name__)


# ============================================
# ç»´åº¦è¡¨åˆå§‹åŒ–æ•°æ®
# ============================================

# åœ°åŒºç»´åº¦æ•°æ®
REGIONS = [
    ('region_001', 'åä¸œ', 1, None, 'ä¸­å›½ä¸œéƒ¨åœ°åŒº'),
    ('region_002', 'åå—', 1, None, 'ä¸­å›½å—éƒ¨åœ°åŒº'),
    ('region_003', 'ååŒ—', 1, None, 'ä¸­å›½åŒ—éƒ¨åœ°åŒº'),
    ('region_004', 'è¥¿å—', 2, None, 'ä¸­å›½è¥¿å—åœ°åŒº'),
    ('region_005', 'ä¸œåŒ—', 2, None, 'ä¸­å›½ä¸œåŒ—åœ°åŒº'),
    ('region_006', 'åä¸­', 2, None, 'ä¸­å›½ä¸­éƒ¨åœ°åŒº'),
    ('region_007', 'è¥¿åŒ—', 3, None, 'ä¸­å›½è¥¿åŒ—åœ°åŒº'),
]

# å“ç±»ç»´åº¦æ•°æ®
CATEGORIES = [
    ('category_001', 'ç”µå­äº§å“', None, 1, 'ç”µå­äº§å“å“ç±»'),
    ('category_001_001', 'æ‰‹æœº', 'category_001', 2, 'æ‰‹æœºå“ç±»'),
    ('category_001_002', 'ç”µè„‘', 'category_001', 2, 'ç”µè„‘å“ç±»'),
    ('category_001_003', 'å¹³æ¿', 'category_001', 2, 'å¹³æ¿å“ç±»'),
    ('category_002', 'æœè£…é‹å¸½', None, 1, 'æœè£…é‹å¸½å“ç±»'),
    ('category_002_001', 'ç”·è£…', 'category_002', 2, 'ç”·è£…å“ç±»'),
    ('category_002_002', 'å¥³è£…', 'category_002', 2, 'å¥³è£…å“ç±»'),
    ('category_002_003', 'è¿åŠ¨é‹', 'category_002', 2, 'è¿åŠ¨é‹å“ç±»'),
    ('category_003', 'å®¶å±…ç”¨å“', None, 1, 'å®¶å±…ç”¨å“å“ç±»'),
    ('category_003_001', 'å®¶å…·', 'category_003', 2, 'å®¶å…·å“ç±»'),
    ('category_003_002', 'å¨å…·', 'category_003', 2, 'å¨å…·å“ç±»'),
]

# æ¸ é“ç»´åº¦æ•°æ®
CHANNELS = [
    ('channel_001', 'APP', 'mobile', 'ç§»åŠ¨åº”ç”¨APP'),
    ('channel_002', 'å°ç¨‹åº', 'miniprogram', 'å¾®ä¿¡å°ç¨‹åº'),
    ('channel_003', 'H5', 'web', 'ç§»åŠ¨ç½‘é¡µH5'),
    ('channel_004', 'PC', 'web', 'PCç½‘é¡µç«¯'),
]

# ç”¨æˆ·ç­‰çº§ç»´åº¦æ•°æ®
USER_LEVELS = [
    ('level_001', 'æ™®é€šä¼šå‘˜', 0, 999, 'åŸºç¡€ä¼šå‘˜æƒç›Š'),
    ('level_002', 'é»„é‡‘ä¼šå‘˜', 1000, 4999, 'é»„é‡‘ä¼šå‘˜æƒç›Š'),
    ('level_003', 'é“‚é‡‘ä¼šå‘˜', 5000, 19999, 'é“‚é‡‘ä¼šå‘˜æƒç›Š'),
    ('level_004', 'é’»çŸ³ä¼šå‘˜', 20000, None, 'é’»çŸ³ä¼šå‘˜æƒç›Š'),
]


def init_dimension_tables():
    """åˆå§‹åŒ–ç»´åº¦è¡¨æ•°æ®."""
    logger.info("ğŸ”„ å¼€å§‹åˆå§‹åŒ–ç»´åº¦è¡¨æ•°æ®...")

    try:
        # 1. åˆå§‹åŒ–åœ°åŒºç»´åº¦
        logger.info("  â¤ åˆå§‹åŒ–åœ°åŒºç»´åº¦è¡¨...")
        postgres_client.execute_update(
            "DELETE FROM dim_region;"
        )
        for region in REGIONS:
            postgres_client.execute_update(
                """INSERT INTO dim_region (region_id, region_name, tier, parent_region_id, description)
                   VALUES (%s, %s, %s, %s, %s)""",
                region
            )
        logger.info(f"  âœ… åœ°åŒºç»´åº¦åˆå§‹åŒ–å®Œæˆ: {len(REGIONS)} æ¡")

        # 2. åˆå§‹åŒ–å“ç±»ç»´åº¦
        logger.info("  â¤ åˆå§‹åŒ–å“ç±»ç»´åº¦è¡¨...")
        postgres_client.execute_update(
            "DELETE FROM dim_category;"
        )
        for category in CATEGORIES:
            postgres_client.execute_update(
                """INSERT INTO dim_category (category_id, category_name, parent_category_id, level, description)
                   VALUES (%s, %s, %s, %s, %s)""",
                category
            )
        logger.info(f"  âœ… å“ç±»ç»´åº¦åˆå§‹åŒ–å®Œæˆ: {len(CATEGORIES)} æ¡")

        # 3. åˆå§‹åŒ–æ¸ é“ç»´åº¦
        logger.info("  â¤ åˆå§‹åŒ–æ¸ é“ç»´åº¦è¡¨...")
        postgres_client.execute_update(
            "DELETE FROM dim_channel;"
        )
        for channel in CHANNELS:
            postgres_client.execute_update(
                """INSERT INTO dim_channel (channel_id, channel_name, channel_type, description)
                   VALUES (%s, %s, %s, %s)""",
                channel
            )
        logger.info(f"  âœ… æ¸ é“ç»´åº¦åˆå§‹åŒ–å®Œæˆ: {len(CHANNELS)} æ¡")

        # 4. åˆå§‹åŒ–ç”¨æˆ·ç­‰çº§ç»´åº¦
        logger.info("  â¤ åˆå§‹åŒ–ç”¨æˆ·ç­‰çº§ç»´åº¦è¡¨...")
        postgres_client.execute_update(
            "DELETE FROM dim_user_level;"
        )
        for level in USER_LEVELS:
            postgres_client.execute_update(
                """INSERT INTO dim_user_level (level_id, level_name, min_points, max_points, benefits)
                   VALUES (%s, %s, %s, %s, %s)""",
                level
            )
        logger.info(f"  âœ… ç”¨æˆ·ç­‰çº§ç»´åº¦åˆå§‹åŒ–å®Œæˆ: {len(USER_LEVELS)} æ¡")

        logger.info("âœ… ç»´åº¦è¡¨åˆå§‹åŒ–å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ ç»´åº¦è¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def init_date_dimension(start_date: datetime, end_date: datetime):
    """åˆå§‹åŒ–æ—¥æœŸç»´åº¦è¡¨.

    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
    """
    logger.info("ğŸ”„ å¼€å§‹åˆå§‹åŒ–æ—¥æœŸç»´åº¦è¡¨...")

    try:
        # æ¸…ç©ºç°æœ‰æ•°æ®
        postgres_client.execute_update("DELETE FROM dim_date;")

        # ç”Ÿæˆæ—¥æœŸç»´åº¦æ•°æ®
        date_list = []
        current_date = start_date

        while current_date <= end_date:
            date_key = int(current_date.strftime('%Y%m%d'))
            year = current_date.year
            quarter = (current_date.month - 1) // 3 + 1
            month = current_date.month
            week = current_date.isocalendar()[1]
            day = current_date.day
            day_of_week = current_date.weekday() + 1  # 1=å‘¨ä¸€, 7=å‘¨æ—¥

            day_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
            month_names = ['ä¸€æœˆ', 'äºŒæœˆ', 'ä¸‰æœˆ', 'å››æœˆ', 'äº”æœˆ', 'å…­æœˆ',
                          'ä¸ƒæœˆ', 'å…«æœˆ', 'ä¹æœˆ', 'åæœˆ', 'åä¸€æœˆ', 'åäºŒæœˆ']

            is_weekend = day_of_week in [6, 7]  # å‘¨å…­æˆ–å‘¨æ—¥
            is_holiday = False  # ç®€åŒ–å¤„ç†ï¼Œä¸åˆ¤æ–­èŠ‚å‡æ—¥
            holiday_name = None

            date_list.append((
                date_key, current_date, year, quarter, month, week, day,
                day_of_week, day_names[day_of_week - 1], month_names[month - 1],
                is_weekend, is_holiday, holiday_name
            ))

            current_date += timedelta(days=1)

        # æ‰¹é‡æ’å…¥
        postgres_client.execute_batch(
            """INSERT INTO dim_date
               (date_key, date, year, quarter, month, week, day,
                day_of_week, day_name, month_name, is_weekend, is_holiday, holiday_name)
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""",
            date_list
        )

        logger.info(f"âœ… æ—¥æœŸç»´åº¦åˆå§‹åŒ–å®Œæˆ: {len(date_list)} å¤©")
        return True

    except Exception as e:
        logger.error(f"âŒ æ—¥æœŸç»´åº¦åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def generate_fact_orders_data(days: int = 30):
    """ç”Ÿæˆè®¢å•äº‹å®è¡¨æµ‹è¯•æ•°æ®.

    Args:
        days: ç”Ÿæˆå¤©æ•°
    """
    logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆè®¢å•äº‹å®è¡¨æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")

    try:
        # æ¸…ç©ºç°æœ‰æ•°æ®
        postgres_client.execute_update("DELETE FROM fact_orders;")

        # è·å–ç»´åº¦é”®å€¼æ˜ å°„
        regions = postgres_client.execute_query("SELECT region_key FROM dim_region;")
        categories = postgres_client.execute_query("SELECT category_key FROM dim_category;")
        channels = postgres_client.execute_query("SELECT channel_key FROM dim_channel;")
        user_levels = postgres_client.execute_query("SELECT level_key FROM dim_user_level;")
        dates = postgres_client.execute_query(
            "SELECT date_key FROM dim_date ORDER BY date DESC LIMIT %s;",
            (days,)
        )

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        data_list = []
        for date_row in dates:
            date_key = date_row['date_key']

            # æ¯å¤©ç”Ÿæˆ 100-500 æ¡èšåˆè®°å½•
            for _ in range(random.randint(100, 500)):
                order_count = random.randint(1, 1000)
                total_order_amount = random.uniform(10000, 500000)
                total_discount = random.uniform(0, total_order_amount * 0.2)
                gmv = total_order_amount - total_discount

                data_list.append((
                    date_key,
                    random.choice(regions)['region_key'],
                    random.choice(categories)['category_key'],
                    random.choice(channels)['channel_key'],
                    random.choice(user_levels)['level_key'],
                    order_count,
                    round(total_order_amount, 2),
                    round(total_discount, 2),
                    round(gmv, 2)
                ))

        # æ‰¹é‡æ’å…¥
        postgres_client.execute_batch(
            """INSERT INTO fact_orders
               (date_key, region_key, category_key, channel_key, user_level_key,
                order_count, total_order_amount, total_discount, gmv)
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)""",
            data_list
        )

        logger.info(f"âœ… è®¢å•äº‹å®è¡¨æ•°æ®ç”Ÿæˆå®Œæˆ: {len(data_list)} æ¡è®°å½•")
        return True

    except Exception as e:
        logger.error(f"âŒ è®¢å•äº‹å®è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return False


def generate_fact_user_activity_data(days: int = 30):
    """ç”Ÿæˆç”¨æˆ·æ´»è·ƒåº¦äº‹å®è¡¨æµ‹è¯•æ•°æ®.

    Args:
        days: ç”Ÿæˆå¤©æ•°
    """
    logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆç”¨æˆ·æ´»è·ƒåº¦äº‹å®è¡¨æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")

    try:
        # æ¸…ç©ºç°æœ‰æ•°æ®
        postgres_client.execute_update("DELETE FROM fact_user_activity;")

        # è·å–ç»´åº¦é”®å€¼æ˜ å°„
        regions = postgres_client.execute_query("SELECT region_key FROM dim_region;")
        channels = postgres_client.execute_query("SELECT channel_key FROM dim_channel;")
        user_levels = postgres_client.execute_query("SELECT level_key FROM dim_user_level;")
        dates = postgres_client.execute_query(
            "SELECT date_key FROM dim_date ORDER BY date DESC LIMIT %s;",
            (days,)
        )

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        data_list = []
        for date_row in dates:
            date_key = date_row['date_key']

            # æ¯å¤©ç”Ÿæˆ 50-200 æ¡èšåˆè®°å½•
            for _ in range(random.randint(50, 200)):
                dau = random.randint(1000, 100000)
                mau = random.randint(dau, int(dau * 3))
                new_users = random.randint(100, 10000)
                returning_users = dau - new_users
                session_count = random.randint(dau, dau * 5)
                avg_session_duration = random.uniform(60, 600)  # 1-10åˆ†é’Ÿ
                page_views = random.randint(session_count * 2, session_count * 10)

                data_list.append((
                    date_key,
                    random.choice(regions)['region_key'],
                    random.choice(channels)['channel_key'],
                    random.choice(user_levels)['level_key'],
                    dau,
                    mau,
                    new_users,
                    returning_users,
                    session_count,
                    round(avg_session_duration, 2),
                    page_views,
                    round(random.uniform(0.3, 0.6), 4),  # retention_day1
                    round(random.uniform(0.2, 0.4), 4),  # retention_day7
                    round(random.uniform(0.1, 0.3), 4),  # retention_day30
                ))

        # æ‰¹é‡æ’å…¥
        postgres_client.execute_batch(
            """INSERT INTO fact_user_activity
               (date_key, region_key, channel_key, user_level_key,
                dau, mau, new_users, returning_users, session_count,
                avg_session_duration, page_views, retention_day1, retention_day7, retention_day30)
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""",
            data_list
        )

        logger.info(f"âœ… ç”¨æˆ·æ´»è·ƒåº¦äº‹å®è¡¨æ•°æ®ç”Ÿæˆå®Œæˆ: {len(data_list)} æ¡è®°å½•")
        return True

    except Exception as e:
        logger.error(f"âŒ ç”¨æˆ·æ´»è·ƒåº¦äº‹å®è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return False


def generate_fact_traffic_data(days: int = 30):
    """ç”Ÿæˆæµé‡äº‹å®è¡¨æµ‹è¯•æ•°æ®.

    Args:
        days: ç”Ÿæˆå¤©æ•°
    """
    logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆæµé‡äº‹å®è¡¨æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")

    try:
        postgres_client.execute_update("DELETE FROM fact_traffic;")

        regions = postgres_client.execute_query("SELECT region_key FROM dim_region;")
        channels = postgres_client.execute_query("SELECT channel_key FROM dim_channel;")
        dates = postgres_client.execute_query(
            "SELECT date_key FROM dim_date ORDER BY date DESC LIMIT %s;",
            (days,)
        )

        data_list = []
        for date_row in dates:
            date_key = date_row['date_key']

            for _ in range(random.randint(50, 200)):
                visitors = random.randint(10000, 500000)
                page_views = random.randint(visitors * 2, visitors * 10)
                unique_visitors = random.randint(int(visitors * 0.7), visitors)
                add_to_cart_count = random.randint(int(visitors * 0.1), int(visitors * 0.3))
                checkout_count = random.randint(int(add_to_cart_count * 0.3), int(add_to_cart_count * 0.6))
                order_count = random.randint(int(checkout_count * 0.5), int(checkout_count * 0.8))

                data_list.append((
                    date_key,
                    random.choice(regions)['region_key'],
                    random.choice(channels)['channel_key'],
                    visitors,
                    page_views,
                    unique_visitors,
                    add_to_cart_count,
                    checkout_count,
                    order_count
                ))

        postgres_client.execute_batch(
            """INSERT INTO fact_traffic
               (date_key, region_key, channel_key,
                visitors, page_views, unique_visitors,
                add_to_cart_count, checkout_count, order_count)
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)""",
            data_list
        )

        logger.info(f"âœ… æµé‡äº‹å®è¡¨æ•°æ®ç”Ÿæˆå®Œæˆ: {len(data_list)} æ¡è®°å½•")
        return True

    except Exception as e:
        logger.error(f"âŒ æµé‡äº‹å®è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return False


def generate_fact_revenue_data(days: int = 30):
    """ç”Ÿæˆæ”¶å…¥äº‹å®è¡¨æµ‹è¯•æ•°æ®.

    Args:
        days: ç”Ÿæˆå¤©æ•°
    """
    logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆæ”¶å…¥äº‹å®è¡¨æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")

    try:
        postgres_client.execute_update("DELETE FROM fact_revenue;")

        regions = postgres_client.execute_query("SELECT region_key FROM dim_region;")
        user_levels = postgres_client.execute_query("SELECT level_key FROM dim_user_level;")
        dates = postgres_client.execute_query(
            "SELECT date_key FROM dim_date ORDER BY date DESC LIMIT %s;",
            (days,)
        )

        data_list = []
        for date_row in dates:
            date_key = date_row['date_key']

            for _ in range(random.randint(30, 100)):
                total_users = random.randint(10000, 100000)
                paying_users = random.randint(int(total_users * 0.1), int(total_users * 0.3))
                total_revenue = random.uniform(100000, 5000000)

                data_list.append((
                    date_key,
                    random.choice(regions)['region_key'],
                    random.choice(user_levels)['level_key'],
                    round(total_revenue, 2),
                    total_users,
                    paying_users,
                    round(random.uniform(100, 1000), 2),  # ltv_30d
                    round(random.uniform(500, 3000), 2),  # ltv_90d
                    round(random.uniform(1000, 10000), 2),  # ltv_365d
                ))

        postgres_client.execute_batch(
            """INSERT INTO fact_revenue
               (date_key, region_key, user_level_key,
                total_revenue, total_users, paying_users, ltv_30d, ltv_90d, ltv_365d)
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)""",
            data_list
        )

        logger.info(f"âœ… æ”¶å…¥äº‹å®è¡¨æ•°æ®ç”Ÿæˆå®Œæˆ: {len(data_list)} æ¡è®°å½•")
        return True

    except Exception as e:
        logger.error(f"âŒ æ”¶å…¥äº‹å®è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return False


def generate_fact_finance_data(days: int = 30):
    """ç”Ÿæˆè´¢åŠ¡äº‹å®è¡¨æµ‹è¯•æ•°æ®.

    Args:
        days: ç”Ÿæˆå¤©æ•°
    """
    logger.info(f"ğŸ”„ å¼€å§‹ç”Ÿæˆè´¢åŠ¡äº‹å®è¡¨æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")

    try:
        postgres_client.execute_update("DELETE FROM fact_finance;")

        regions = postgres_client.execute_query("SELECT region_key FROM dim_region;")
        dates = postgres_client.execute_query(
            "SELECT date_key FROM dim_date ORDER BY date DESC LIMIT %s;",
            (days,)
        )

        data_list = []
        for date_row in dates:
            date_key = date_row['date_key']

            for _ in range(len(regions)):
                revenue = random.uniform(500000, 10000000)
                cost_of_goods_sold = random.uniform(revenue * 0.3, revenue * 0.5)
                operating_expense = random.uniform(revenue * 0.2, revenue * 0.4)
                marketing_cost = random.uniform(revenue * 0.1, revenue * 0.3)

                data_list.append((
                    date_key,
                    random.choice(regions)['region_key'],
                    round(revenue, 2),
                    round(cost_of_goods_sold, 2),
                    round(operating_expense, 2),
                    round(marketing_cost, 2)
                ))

        postgres_client.execute_batch(
            """INSERT INTO fact_finance
               (date_key, region_key, revenue, cost_of_goods_sold, operating_expense, marketing_cost)
               VALUES (%s, %s, %s, %s, %s, %s)""",
            data_list
        )

        logger.info(f"âœ… è´¢åŠ¡äº‹å®è¡¨æ•°æ®ç”Ÿæˆå®Œæˆ: {len(data_list)} æ¡è®°å½•")
        return True

    except Exception as e:
        logger.error(f"âŒ è´¢åŠ¡äº‹å®è¡¨æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return False


def init_all_test_data(days: int = 30):
    """åˆå§‹åŒ–æ‰€æœ‰æµ‹è¯•æ•°æ®.

    Args:
        days: ç”Ÿæˆå¤©æ•°
    """
    logger.info("=" * 60)
    logger.info("å¼€å§‹åˆå§‹åŒ–PostgreSQLæµ‹è¯•æ•°æ®")
    logger.info("=" * 60)

    # 1. åˆå§‹åŒ–ç»´åº¦è¡¨
    if not init_dimension_tables():
        logger.error("âŒ ç»´åº¦è¡¨åˆå§‹åŒ–å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
        return False

    # 2. åˆå§‹åŒ–æ—¥æœŸç»´åº¦ï¼ˆæœ€è¿‘1å¹´ï¼‰
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)
    if not init_date_dimension(start_date, end_date):
        logger.error("âŒ æ—¥æœŸç»´åº¦åˆå§‹åŒ–å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
        return False

    # 3. ç”Ÿæˆäº‹å®è¡¨æµ‹è¯•æ•°æ®
    results = []
    results.append(generate_fact_orders_data(days))
    results.append(generate_fact_user_activity_data(days))
    results.append(generate_fact_traffic_data(days))
    results.append(generate_fact_revenue_data(days))
    results.append(generate_fact_finance_data(days))

    if all(results):
        logger.info("=" * 60)
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•æ•°æ®åˆå§‹åŒ–å®Œæˆ")
        logger.info("=" * 60)
        return True
    else:
        logger.error("âŒ éƒ¨åˆ†äº‹å®è¡¨æ•°æ®åˆå§‹åŒ–å¤±è´¥")
        return False


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    if not postgres_client.test_connection():
        logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        exit(1)

    # åˆå§‹åŒ–æµ‹è¯•æ•°æ®ï¼ˆæœ€è¿‘30å¤©ï¼‰
    init_all_test_data(days=30)
