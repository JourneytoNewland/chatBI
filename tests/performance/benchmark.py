"""æ€§èƒ½åŸºå‡†æµ‹è¯• - å»ºç«‹æ€§èƒ½baseline."""

import time
import statistics
from typing import Dict, List, Any
from dataclasses import dataclass
import json


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ."""
    
    name: str
    total_runs: int
    successful_runs: int
    failed_runs: int
    
    # å»¶è¿Ÿç»Ÿè®¡ï¼ˆæ¯«ç§’ï¼‰
    p50: float
    p75: float
    p95: float
    p99: float
    avg: float
    min: float
    max: float
    
    # ååé‡
    rps: float  # Requests Per Second
    
    # é”™è¯¯ä¿¡æ¯
    errors: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸."""
        return {
            "name": self.name,
            "total_runs": self.total_runs,
            "successful_runs": self.successful_runs,
            "failed_runs": self.failed_runs,
            "success_rate": f"{(self.successful_runs / self.total_runs * 100):.2f}%" if self.total_runs > 0 else "N/A",
            "latency_ms": {
                "p50": f"{self.p50:.2f}",
                "p75": f"{self.75:.2f}",
                "p95": f"{self.p95:.2f}",
                "p99": f"{self.p99:.2f}",
                "avg": f"{self.avg:.2f}",
                "min": f"{self.min:.2f}",
                "max": f"{self.max:.2f}",
            },
            "throughput_rps": f"{self.rps:.2f}",
            "errors": self.errors[:5]  # åªä¿ç•™å‰5ä¸ªé”™è¯¯
        }


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·."""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        """åˆå§‹åŒ–åŸºå‡†æµ‹è¯•å·¥å…·.
        
        Args:
            base_url: APIåŸºç¡€URL
        """
        self.base_url = base_url
        self.session = None
        
    def _get_session(self):
        """è·å–HTTPä¼šè¯."""
        if self.session is None:
            import requests
            self.session = requests.Session()
        return self.session
    
    def run_benchmark(
        self,
        query: str,
        warmup_runs: int = 5,
        benchmark_runs: int = 50,
        timeout: int = 30
    ) -> BenchmarkResult:
        """è¿è¡Œå•ä¸ªæŸ¥è¯¢çš„åŸºå‡†æµ‹è¯•.
        
        Args:
            query: æµ‹è¯•æŸ¥è¯¢
            warmup_runs: é¢„çƒ­æ¬¡æ•°
            benchmark_runs: åŸºå‡†æµ‹è¯•æ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            BenchmarkResult: åŸºå‡†æµ‹è¯•ç»“æœ
        """
        print(f"\nğŸ”„ è¿è¡ŒåŸºå‡†æµ‹è¯•: {query}")
        print(f"   é¢„çƒ­: {warmup_runs} æ¬¡")
        print(f"   åŸºå‡†æµ‹è¯•: {benchmark_runs} æ¬¡")
        
        session = self._get_session()
        latencies = []
        errors = []
        
        # 1. é¢„çƒ­ï¼ˆé¿å…å†·å¯åŠ¨å½±å“ï¼‰
        print("   â³ é¢„çƒ­ä¸­...")
        for i in range(warmup_runs):
            try:
                start = time.time()
                response = session.post(
                    f"{self.base_url}/api/v3/query",
                    json={"query": query},
                    timeout=timeout
                )
                elapsed = (time.time() - start) * 1000
                print(f"     é¢„çƒ­ {i+1}/{warmup_runs}: {elapsed:.2f}ms")
            except Exception as e:
                print(f"     é¢„çƒ­å¤±è´¥: {e}")
        
        # 2. åŸºå‡†æµ‹è¯•
        print(f"   â³ åŸºå‡†æµ‹è¯•ä¸­...")
        total_start = time.time()
        
        for i in range(benchmark_runs):
            try:
                start = time.time()
                response = session.post(
                    f"{self.base_url}/api/v3/query",
                    json={"query": query},
                    timeout=timeout
                )
                elapsed = (time.time() - start) * 1000
                
                if response.status_code == 200:
                    latencies.append(elapsed)
                    if (i + 1) % 10 == 0:
                        print(f"     è¿›åº¦: {i+1}/{benchmark_runs}")
                else:
                    errors.append(f"HTTP {response.status_code}")
                    
            except Exception as e:
                errors.append(str(e))
        
        total_time = time.time() - total_start
        
        # 3. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        if latencies:
            latencies_sorted = sorted(latencies)
            
            result = BenchmarkResult(
                name=query,
                total_runs=benchmark_runs,
                successful_runs=len(latencies),
                failed_runs=len(errors),
                p50=latencies_sorted[int(len(latencies_sorted) * 0.50)],
                p75=latencies_sorted[int(len(latencies_sorted) * 0.75)],
                p95=latencies_sorted[int(len(latencies_sorted) * 0.95)],
                p99=latencies_sorted[int(len(latencies_sorted) * 0.99)],
                avg=statistics.mean(latencies),
                min=min(latencies),
                max=max(latencies),
                rps=len(latencies) / total_time if total_time > 0 else 0,
                errors=errors
            )
        else:
            result = BenchmarkResult(
                name=query,
                total_runs=benchmark_runs,
                successful_runs=0,
                failed_runs=len(errors),
                p50=0, p75=0, p95=0, p99=0, avg=0, min=0, max=0,
                rps=0,
                errors=errors
            )
        
        # 4. è¾“å‡ºç»“æœ
        print(f"\n   âœ… æµ‹è¯•å®Œæˆ")
        print(f"   æˆåŠŸç‡: {result.successful_runs}/{result.total_runs} ({result.successful_runs/result.total_runs*100 if result.total_runs > 0 else 0:.1f}%)")
        print(f"   å»¶è¿Ÿç»Ÿè®¡:")
        print(f"     P50:  {result.p50:.2f}ms")
        print(f"     P75:  {result.p75:.2f}ms")
        print(f"     P95:  {result.p95:.2f}ms")
        print(f"     P99:  {result.p99:.2f}ms")
        print(f"     å¹³å‡: {result.avg:.2f}ms")
        print(f"   ååé‡: {result.rps:.2f} RPS")
        
        if result.errors:
            print(f"   é”™è¯¯æ•°: {len(result.errors)}")
            print(f"   é”™è¯¯ç¤ºä¾‹: {result.errors[:3]}")
        
        return result
    
    def run_suite(self, queries: List[str], **kwargs) -> List[BenchmarkResult]:
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•å¥—ä»¶.
        
        Args:
            queries: æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
            **kwargs: ä¼ é€’ç»™run_benchmarkçš„å‚æ•°
        
        Returns:
            List[BenchmarkResult]: æ‰€æœ‰æµ‹è¯•ç»“æœ
        """
        print("=" * 60)
        print("ğŸš€ chatBI æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶")
        print("=" * 60)
        print(f"ç›®æ ‡æœåŠ¡å™¨: {self.base_url}")
        print(f"æµ‹è¯•æŸ¥è¯¢æ•°: {len(queries)}")
        print()
        
        results = []
        
        for i, query in enumerate(queries):
            print(f"\n[{i+1}/{len(queries)}]", end=" ")
            result = self.run_benchmark(query, **kwargs)
            results.append(result)
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self._print_summary(results)
        
        return results
    
    def _print_summary(self, results: List[BenchmarkResult]):
        """æ‰“å°æµ‹è¯•æ±‡æ€»æŠ¥å‘Š.
        
        Args:
            results: æµ‹è¯•ç»“æœåˆ—è¡¨
        """
        print("\n" + "=" * 60)
        print("ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        print("=" * 60)
        
        print(f"\n{'æŸ¥è¯¢':<30} {'P50':<10} {'P95':<10} {'P99':<10} {'æˆåŠŸç‡':<10}")
        print("-" * 70)
        
        for result in results:
            success_rate = f"{result.successful_runs/result.total_runs*100:.1f}%" if result.total_runs > 0 else "N/A"
            print(f"{result.name:<30} {result.p50:<10.2f} {result.p95:<10.2f} {result.p99:<10.2f} {success_rate:<10}")
        
        # æ•´ä½“ç»Ÿè®¡
        all_p95 = [r.p95 for r in results if r.successful_runs > 0]
        all_p99 = [r.p99 for r in results if r.successful_runs > 0]
        
        if all_p95:
            print("\næ•´ä½“æ€§èƒ½:")
            print(f"  å¹³å‡P95å»¶è¿Ÿ: {statistics.mean(all_p95):.2f}ms")
            print(f"  æœ€å¤§P95å»¶è¿Ÿ: {max(all_p95):.2f}ms")
            print(f"  å¹³å‡P99å»¶è¿Ÿ: {statistics.mean(all_p99):.2f}ms")
            print(f"  æœ€å¤§P99å»¶è¿Ÿ: {max(all_p99):.2f}ms")
        
        # æ€§èƒ½è¯„çº§
        print("\næ€§èƒ½è¯„çº§:")
        avg_p95 = statistics.mean(all_p95) if all_p95 else 0
        
        if avg_p95 < 100:
            grade = "âœ… ä¼˜ç§€ (<100ms)"
        elif avg_p95 < 300:
            grade = "ğŸŸ¡ è‰¯å¥½ (<300ms)"
        elif avg_p95 < 500:
            grade = "ğŸŸ  ä¸€èˆ¬ (<500ms)"
        else:
            grade = "ğŸ”´ éœ€ä¼˜åŒ– (>500ms)"
        
        print(f"  {grade}")
        
        print("\n" + "=" * 60)
    
    def save_results(self, results: List[BenchmarkResult], filename: str):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶.
        
        Args:
            results: æµ‹è¯•ç»“æœåˆ—è¡¨
            filename: æ–‡ä»¶å
        """
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(
                [r.to_dict() for r in results],
                f,
                ensure_ascii=False,
                indent=2
            )
        
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")


# é¢„å®šä¹‰æµ‹è¯•æŸ¥è¯¢å¥—ä»¶
BENCHMARK_QUERIES = [
    # ç®€å•æŸ¥è¯¢
    "GMV",
    "DAU",
    "è¥æ”¶",
    "è½¬åŒ–ç‡",
    
    # æ—¶é—´èŒƒå›´æŸ¥è¯¢
    "æœ€è¿‘7å¤©GMV",
    "æœ¬æœˆè¥æ”¶æ€»å’Œ",
    "æœ€è¿‘30å¤©DAU",
    "æœ¬å‘¨è®¢å•é‡",
    
    # ç»´åº¦æŸ¥è¯¢
    "æŒ‰åœ°åŒºGMV",
    "æŒ‰æ¸ é“ç»Ÿè®¡DAU",
    "æŒ‰å“ç±»æˆäº¤é‡‘é¢",
    
    # å¤æ‚æŸ¥è¯¢
    "æœ€è¿‘7å¤©æŒ‰åœ°åŒºç»Ÿè®¡GMVæ€»å’Œ",
    "æœ¬æœˆæŒ‰æ¸ é“ç»Ÿè®¡DAU",
]


if __name__ == "__main__":
    import sys
    
    # é…ç½®
    BASE_URL = sys.argv[1] if len(sys.argv) > 1 else "http://localhost:8000"
    WARMUP_RUNS = 5
    BENCHMARK_RUNS = 50
    
    print("ğŸ“‹ é…ç½®:")
    print(f"  æœåŠ¡å™¨: {BASE_URL}")
    print(f"  é¢„çƒ­æ¬¡æ•°: {WARMUP_RUNS}")
    print(f"  åŸºå‡†æµ‹è¯•æ¬¡æ•°: {BENCHMARK_RUNS}")
    print()
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark = PerformanceBenchmark(BASE_URL)
    results = benchmark.run_suite(
        BENCHMARK_QUERIES,
        warmup_runs=WARMUP_RUNS,
        benchmark_runs=BENCHMARK_RUNS
    )
    
    # ä¿å­˜ç»“æœ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    output_file = f"tests/performance/results/benchmark_{timestamp}.json"
    benchmark.save_results(results, output_file)
    
    print("\nâœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼")
